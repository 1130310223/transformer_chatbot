{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data, row_labels, col_labels, ax=None,\n",
    "            cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "\n",
    "    Arguments:\n",
    "        data       : A 2D numpy array of shape (N,M)\n",
    "        row_labels : A list or array of length N with the labels\n",
    "                     for the rows\n",
    "        col_labels : A list or array of length M with the labels\n",
    "                     for the columns\n",
    "    Optional arguments:\n",
    "        ax         : A matplotlib.axes.Axes instance to which the heatmap\n",
    "                     is plotted. If not provided, use current axes or\n",
    "                     create a new one.\n",
    "        cbar_kw    : A dictionary with arguments to\n",
    "                     :meth:`matplotlib.Figure.colorbar`.\n",
    "        cbarlabel  : The label for the colorbar\n",
    "    All other arguments are directly passed on to the imshow call.\n",
    "    \"\"\"\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    # ... and label them with the respective list entries.\n",
    "    ax.set_xticklabels(col_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False,\n",
    "                   labeltop=True, labelbottom=False)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    for edge, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    return im, cbar\n",
    "\n",
    "\n",
    "def annotate_heatmap(im, data=None, valfmt=\"{x:.2f}\",\n",
    "                     textcolors=[\"black\", \"white\"],\n",
    "                     threshold=None, **textkw):\n",
    "    \"\"\"\n",
    "    A function to annotate a heatmap.\n",
    "\n",
    "    Arguments:\n",
    "        im         : The AxesImage to be labeled.\n",
    "    Optional arguments:\n",
    "        data       : Data used to annotate. If None, the image's data is used.\n",
    "        valfmt     : The format of the annotations inside the heatmap.\n",
    "                     This should either use the string format method, e.g.\n",
    "                     \"$ {x:.2f}\", or be a :class:`matplotlib.ticker.Formatter`.\n",
    "        textcolors : A list or array of two color specifications. The first is\n",
    "                     used for values below a threshold, the second for those\n",
    "                     above.\n",
    "        threshold  : Value in data units according to which the colors from\n",
    "                     textcolors are applied. If None (the default) uses the\n",
    "                     middle of the colormap as separation.\n",
    "\n",
    "    Further arguments are passed on to the created text labels.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[im.norm(data[i, j]) > threshold])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘checkpoints’: File exists\n",
      "--2018-12-30 12:50:51--  https://www.dropbox.com/s/cs6zd9yntn6ixea/last_checkpoint?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.70.1, 2620:100:6026:1::a27d:4601\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.70.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/dl/cs6zd9yntn6ixea/last_checkpoint [following]\n",
      "--2018-12-30 12:50:51--  https://www.dropbox.com/s/dl/cs6zd9yntn6ixea/last_checkpoint\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uce6bca547ca5c3213df6b9eba31.dl.dropboxusercontent.com/cd/0/get/AYfI1M7No_5wo9pUFrR1rwngKmOGHM5jP5KWBGtEdrqF5RUJXe-hlwGiXABVGodUnepjUjIX8im-4kBC9ftxKb5KGgIiteaV1ODuF3kbLOY6q-czybWShGDjj1w-SlhAP82mFz5__xEzIbLXdlZDNmdq5_UgSaPQB5o9_NGAuPZ7-4VKLw7ZOCGo0hePb394Bz8/file?dl=1 [following]\n",
      "--2018-12-30 12:50:52--  https://uce6bca547ca5c3213df6b9eba31.dl.dropboxusercontent.com/cd/0/get/AYfI1M7No_5wo9pUFrR1rwngKmOGHM5jP5KWBGtEdrqF5RUJXe-hlwGiXABVGodUnepjUjIX8im-4kBC9ftxKb5KGgIiteaV1ODuF3kbLOY6q-czybWShGDjj1w-SlhAP82mFz5__xEzIbLXdlZDNmdq5_UgSaPQB5o9_NGAuPZ7-4VKLw7ZOCGo0hePb394Bz8/file?dl=1\n",
      "Resolving uce6bca547ca5c3213df6b9eba31.dl.dropboxusercontent.com (uce6bca547ca5c3213df6b9eba31.dl.dropboxusercontent.com)... 162.125.70.6, 2620:100:6026:6::a27d:4606\n",
      "Connecting to uce6bca547ca5c3213df6b9eba31.dl.dropboxusercontent.com (uce6bca547ca5c3213df6b9eba31.dl.dropboxusercontent.com)|162.125.70.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1398568932 (1,3G) [application/binary]\n",
      "Saving to: ‘checkpoints/last_checkpoint’\n",
      "\n",
      "checkpoints/last_ch 100%[===================>]   1,30G  2,38MB/s    in 7m 34s  \n",
      "\n",
      "2018-12-30 12:58:26 (2,94 MB/s) - ‘checkpoints/last_checkpoint’ saved [1398568932/1398568932]\n",
      "\n",
      "--2018-12-30 12:58:27--  https://www.dropbox.com/s/n2jbjyq32x6jgr6/parameters.zip?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.70.1, 2620:100:6026:1::a27d:4601\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.70.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/dl/n2jbjyq32x6jgr6/parameters.zip [following]\n",
      "--2018-12-30 12:58:28--  https://www.dropbox.com/s/dl/n2jbjyq32x6jgr6/parameters.zip\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc32ca3cae4c6d0e54c7b57a06fc.dl.dropboxusercontent.com/cd/0/get/AYf38z5Rq8Kvzd0sCNSWFz1Gp0QHozf_7eroyJc5GBJRZ81WMoxJyoHzGi8OMAp6a4HHdW3xgcroayKMKqDo9hXZfilggRkUyCZ9uEUfGcEfnSa7ZgACwlfD-52iU2CTBDBadIOvsD8NtCkpSqe-zVcd4UglcZCVnL7H8EY3hUV2fzwA2VcGfexarGlAaLm1gZA/file?dl=1 [following]\n",
      "--2018-12-30 12:58:29--  https://uc32ca3cae4c6d0e54c7b57a06fc.dl.dropboxusercontent.com/cd/0/get/AYf38z5Rq8Kvzd0sCNSWFz1Gp0QHozf_7eroyJc5GBJRZ81WMoxJyoHzGi8OMAp6a4HHdW3xgcroayKMKqDo9hXZfilggRkUyCZ9uEUfGcEfnSa7ZgACwlfD-52iU2CTBDBadIOvsD8NtCkpSqe-zVcd4UglcZCVnL7H8EY3hUV2fzwA2VcGfexarGlAaLm1gZA/file?dl=1\n",
      "Resolving uc32ca3cae4c6d0e54c7b57a06fc.dl.dropboxusercontent.com (uc32ca3cae4c6d0e54c7b57a06fc.dl.dropboxusercontent.com)... 162.125.70.6, 2620:100:6026:6::a27d:4606\n",
      "Connecting to uc32ca3cae4c6d0e54c7b57a06fc.dl.dropboxusercontent.com (uc32ca3cae4c6d0e54c7b57a06fc.dl.dropboxusercontent.com)|162.125.70.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 308292 (301K) [application/binary]\n",
      "Saving to: ‘parameters.zip’\n",
      "\n",
      "parameters.zip      100%[===================>] 301,07K  1,60MB/s    in 0,2s    \n",
      "\n",
      "2018-12-30 12:58:30 (1,60 MB/s) - ‘parameters.zip’ saved [308292/308292]\n",
      "\n",
      "Archive:  parameters.zip\n",
      "   creating: parameters/\n",
      "  inflating: parameters/bpe.code     \n",
      "  inflating: parameters/bpe.vocab    \n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoints\n",
    "!wget -O checkpoints/last_checkpoint https://www.dropbox.com/s/cs6zd9yntn6ixea/last_checkpoint?dl=1\n",
    "\n",
    "!wget -O parameters.zip https://www.dropbox.com/s/n2jbjyq32x6jgr6/parameters.zip?dl=1\n",
    "!unzip parameters.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.transformer_model import TransformerModel\n",
    "from model.text import BPEVocab\n",
    "from model.utils import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import get_model_config\n",
    "model_config = get_model_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annealing': 0,\n",
      " 'annealing_topk': None,\n",
      " 'attn_dropout': 0.1,\n",
      " 'beam_size': 3,\n",
      " 'bpe_codes_path': './parameters/bpe.code',\n",
      " 'bpe_vocab_path': './parameters/bpe.vocab',\n",
      " 'checkpoint_path': './checkpoints/last_checkpoint',\n",
      " 'diversity_coef': 0,\n",
      " 'diversity_groups': 1,\n",
      " 'dropout': 0.1,\n",
      " 'embed_dropout': 0.1,\n",
      " 'embeddings_size': 768,\n",
      " 'ff_dropout': 0.1,\n",
      " 'length_penalty': 0.6,\n",
      " 'max_seq_len': 256,\n",
      " 'n_heads': 12,\n",
      " 'n_layers': 12,\n",
      " 'n_pos_embeddings': 512,\n",
      " 'n_segments': None}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = BPEVocab.from_files(model_config.bpe_vocab_path, model_config.bpe_codes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(n_layers=model_config.n_layers,\n",
    "                         n_embeddings=len(vocab),\n",
    "                         n_pos_embeddings=model_config.n_pos_embeddings,\n",
    "                         embeddings_size=model_config.embeddings_size,\n",
    "                         padding_idx=vocab.pad_id,\n",
    "                         n_heads=model_config.n_heads,\n",
    "                         dropout=model_config.dropout,\n",
    "                         embed_dropout=model_config.embed_dropout,\n",
    "                         attn_dropout=model_config.attn_dropout,\n",
    "                         ff_dropout=model_config.ff_dropout,\n",
    "                         bos_id=vocab.bos_id,\n",
    "                         eos_id=vocab.eos_id,\n",
    "                         max_seq_len=256,\n",
    "                         beam_size=3,\n",
    "                         length_penalty=0.6,\n",
    "                         n_segments=model_config.n_segments,\n",
    "                         sample=False,\n",
    "                         annealing_topk=None,\n",
    "                         annealing=0.6,\n",
    "                         diversity_coef=0,\n",
    "                         diversity_groups=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (transformer_module): TransformerModule(\n",
       "    (embeddings): Embedding(40485, 768, padding_idx=0)\n",
       "    (pos_embeddings): Embedding(513, 768, padding_idx=0)\n",
       "    (embed_dropout): Dropout(p=0.1)\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (attn_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (attn_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (attn_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (attn_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (attn_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (attn_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (6): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (attn_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (7): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (attn_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (8): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (attn_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (9): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (attn_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (10): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (attn_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (11): TransformerBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (qkv_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (attn_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (ff_norm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_softmax): Linear(in_features=768, out_features=40485, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "state_dict = torch.load(model_config.checkpoint_path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "if 'model' in state_dict:\n",
    "    state_dict = state_dict['model']\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan  2 18:24:57 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 396.24.02              Driver Version: 396.24.02                 |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 1070    Off  | 00000000:03:00.0 Off |                  N/A |\r\n",
      "|  0%   49C    P2    41W / 180W |    967MiB /  8119MiB |     46%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 1070    Off  | 00000000:04:00.0  On |                  N/A |\r\n",
      "|  0%   49C    P8    12W / 180W |     82MiB /  8116MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     18908      C   /opt/anaconda3/bin/python                    955MiB |\r\n",
      "|    1      5034      G   /usr/lib/xorg/Xorg                            69MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_responce(encoded_context, max_len=255):\n",
    "    prevs = [[vocab.bos_id]]\n",
    "    \n",
    "    dump = []\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "#         print(30*'-')\n",
    "#         print(30*'-')\n",
    "#         print(30*'-')\n",
    "        prevs_t = torch.tensor(prevs, dtype=torch.long, device=device)\n",
    "        \n",
    "        current_dump = []\n",
    "        outputs = model.decode(prevs_t, encoded_context, dump=current_dump)\n",
    "\n",
    "        _, m_idx = torch.max(outputs[:, -1, :], dim=-1)\n",
    "        m_idx = m_idx.item()\n",
    "        \n",
    "        dump.append((m_idx, current_dump))\n",
    "\n",
    "        prevs[0].append(m_idx)\n",
    "\n",
    "        if m_idx == vocab.eos_id:\n",
    "            break\n",
    "#         break\n",
    "    return prevs[0], dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_info(max_sequences=4, max_len=255):\n",
    "    info = []\n",
    "    for _ in range(max_sequences):\n",
    "        new_info = input('Info: ').lower().strip()\n",
    "        \n",
    "        if new_info == 'exit':\n",
    "            break\n",
    "        \n",
    "        if not new_info.endswith('.'):\n",
    "            new_info += '.'\n",
    "            \n",
    "#         print(new_info)\n",
    "        \n",
    "        info += vocab.string2ids(new_info)\n",
    "    \n",
    "    if info:\n",
    "        info = [vocab.info_bos_id] + info[:model.n_pos_embeddings-2] + [vocab.info_eos_id]\n",
    "        info = [torch.tensor(info, dtype=torch.long)]\n",
    "        info = pad_sequence(info, batch_first=True, padding_value=vocab.pad_id).to(device)\n",
    "        \n",
    "    return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_interactive():\n",
    "    \n",
    "    info = read_info()\n",
    "#     print('1' if info else '2')\n",
    "#     return\n",
    "    \n",
    "    dialog = []\n",
    "    while True:\n",
    "        new_message = input('H: ').lower().strip()\n",
    "#         print(new_message)\n",
    "        \n",
    "        if new_message == 'exit':\n",
    "            break\n",
    "        \n",
    "        dialog += [vocab.talker1_bos_id] + vocab.string2ids(new_message) + [vocab.talker1_eos_id]\n",
    "        \n",
    "        t_dialog = [torch.tensor(dialog[-model_config.embeddings_size+1:], dtype=torch.long)]\n",
    "        t_dialog = pad_sequence(t_dialog, batch_first=True, padding_value=vocab.pad_id).to(device)\n",
    "        \n",
    "        context = []\n",
    "        if len(info):\n",
    "            context.append(info)\n",
    "        context.append(t_dialog)\n",
    "\n",
    "        encoded_context = [model.encode(c) for c in context]\n",
    "        \n",
    "        res_indx, dump = model_responce(encoded_context)\n",
    "        res_indx = res_indx[1:-1]\n",
    "        \n",
    "        print(f'B: {vocab.ids2string(res_indx)}')\n",
    "        \n",
    "        return dump\n",
    "        \n",
    "        dialog += [vocab.talker2_bos_id] + res_indx + [vocab.talker2_eos_id]\n",
    "        \n",
    "#         print(t_dialog)\n",
    "#         print(dialog)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: exit\n",
      "H: hi\n",
      "layer_num: 0 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 0 | run_i: 0 | - kv_same: True\n",
      "layer_num: 0 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 0 | run_i: 0 | None\n",
      "layer_num: 0 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 0 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 1 | run_i: 0 | - kv_same: True\n",
      "layer_num: 1 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 1 | run_i: 0 | None\n",
      "layer_num: 1 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 1 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 2 | run_i: 0 | - kv_same: True\n",
      "layer_num: 2 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 2 | run_i: 0 | None\n",
      "layer_num: 2 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 2 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 3 | run_i: 0 | - kv_same: True\n",
      "layer_num: 3 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 3 | run_i: 0 | None\n",
      "layer_num: 3 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 3 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 4 | run_i: 0 | - kv_same: True\n",
      "layer_num: 4 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 4 | run_i: 0 | None\n",
      "layer_num: 4 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 4 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 5 | run_i: 0 | - kv_same: True\n",
      "layer_num: 5 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 5 | run_i: 0 | None\n",
      "layer_num: 5 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 5 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 6 | run_i: 0 | - kv_same: True\n",
      "layer_num: 6 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 6 | run_i: 0 | None\n",
      "layer_num: 6 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 6 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 7 | run_i: 0 | - kv_same: True\n",
      "layer_num: 7 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 7 | run_i: 0 | None\n",
      "layer_num: 7 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 7 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 8 | run_i: 0 | - kv_same: True\n",
      "layer_num: 8 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 8 | run_i: 0 | None\n",
      "layer_num: 8 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 8 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 9 | run_i: 0 | - kv_same: True\n",
      "layer_num: 9 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 9 | run_i: 0 | None\n",
      "layer_num: 9 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 9 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 10 | run_i: 0 | - kv_same: True\n",
      "layer_num: 10 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 10 | run_i: 0 | None\n",
      "layer_num: 10 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 10 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 11 | run_i: 0 | - kv_same: True\n",
      "layer_num: 11 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 11 | run_i: 0 | None\n",
      "layer_num: 11 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 11 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 0 | run_i: 0 | - k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 0 | run_i: 0 | - v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 0 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 0 | run_i: 0 | - kv_same: True\n",
      "layer_num: 0 | run_i: 0 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 0 | run_i: 0 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 0 | run_i: 0 | + k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 0 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 0 | run_i: 0 | + v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 0 | run_i: 0 | = v_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 0 | run_i: 0 | _attn | v size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 1, 1])\n",
      "layer_num: 0 | run_i: 0 | dump is not none\n",
      "layer_num: 0 | run_i: 0 | w_sizetorch.Size([1, 12, 1, 1])\n",
      "layer_num: 0 | run_i: 0 | v_sizetorch.Size([1, 12, 1, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 0 | run_i: 1 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 0 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 0 | run_i: 1 | - kv_same: True\n",
      "layer_num: 0 | run_i: 1 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 0 | run_i: 1 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 0 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 1, 3])\n",
      "layer_num: 0 | run_i: 1 | dump is not none\n",
      "layer_num: 0 | run_i: 1 | w_sizetorch.Size([1, 12, 1, 3])\n",
      "layer_num: 0 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 1 | run_i: 0 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 1 | run_i: 0 | - k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 1 | run_i: 0 | - v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 1 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 1 | run_i: 0 | - kv_same: True\n",
      "layer_num: 1 | run_i: 0 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 1 | run_i: 0 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 1 | run_i: 0 | + k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 1 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 1 | run_i: 0 | + v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 1 | run_i: 0 | = v_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 1 | run_i: 0 | _attn | v size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 1, 1])\n",
      "layer_num: 1 | run_i: 0 | dump is not none\n",
      "layer_num: 1 | run_i: 0 | w_sizetorch.Size([1, 12, 1, 1])\n",
      "layer_num: 1 | run_i: 0 | v_sizetorch.Size([1, 12, 1, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 1 | run_i: 1 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 1 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 1 | run_i: 1 | - kv_same: True\n",
      "layer_num: 1 | run_i: 1 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 1 | run_i: 1 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 1 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 1, 3])\n",
      "layer_num: 1 | run_i: 1 | dump is not none\n",
      "layer_num: 1 | run_i: 1 | w_sizetorch.Size([1, 12, 1, 3])\n",
      "layer_num: 1 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 2 | run_i: 0 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 2 | run_i: 0 | - k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 2 | run_i: 0 | - v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 2 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 2 | run_i: 0 | - kv_same: True\n",
      "layer_num: 2 | run_i: 0 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 2 | run_i: 0 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 2 | run_i: 0 | + k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 2 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 2 | run_i: 0 | + v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 2 | run_i: 0 | = v_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 2 | run_i: 0 | _attn | v size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 1, 1])\n",
      "layer_num: 2 | run_i: 0 | dump is not none\n",
      "layer_num: 2 | run_i: 0 | w_sizetorch.Size([1, 12, 1, 1])\n",
      "layer_num: 2 | run_i: 0 | v_sizetorch.Size([1, 12, 1, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 2 | run_i: 1 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 2 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 2 | run_i: 1 | - kv_same: True\n",
      "layer_num: 2 | run_i: 1 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 2 | run_i: 1 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 2 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 1, 3])\n",
      "layer_num: 2 | run_i: 1 | dump is not none\n",
      "layer_num: 2 | run_i: 1 | w_sizetorch.Size([1, 12, 1, 3])\n",
      "layer_num: 2 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 3 | run_i: 0 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 3 | run_i: 0 | - k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 3 | run_i: 0 | - v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 3 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 3 | run_i: 0 | - kv_same: True\n",
      "layer_num: 3 | run_i: 0 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 3 | run_i: 0 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 3 | run_i: 0 | + k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 3 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 3 | run_i: 0 | + v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 3 | run_i: 0 | = v_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 3 | run_i: 0 | _attn | v size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 1, 1])\n",
      "layer_num: 3 | run_i: 0 | dump is not none\n",
      "layer_num: 3 | run_i: 0 | w_sizetorch.Size([1, 12, 1, 1])\n",
      "layer_num: 3 | run_i: 0 | v_sizetorch.Size([1, 12, 1, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 3 | run_i: 1 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 3 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 3 | run_i: 1 | - kv_same: True\n",
      "layer_num: 3 | run_i: 1 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 3 | run_i: 1 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 3 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 1, 3])\n",
      "layer_num: 3 | run_i: 1 | dump is not none\n",
      "layer_num: 3 | run_i: 1 | w_sizetorch.Size([1, 12, 1, 3])\n",
      "layer_num: 3 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 4 | run_i: 0 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 4 | run_i: 0 | - k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 4 | run_i: 0 | - v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 4 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 4 | run_i: 0 | - kv_same: True\n",
      "layer_num: 4 | run_i: 0 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 4 | run_i: 0 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 4 | run_i: 0 | + k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 4 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 4 | run_i: 0 | + v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 4 | run_i: 0 | = v_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 4 | run_i: 0 | _attn | v size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 1, 1])\n",
      "layer_num: 4 | run_i: 0 | dump is not none\n",
      "layer_num: 4 | run_i: 0 | w_sizetorch.Size([1, 12, 1, 1])\n",
      "layer_num: 4 | run_i: 0 | v_sizetorch.Size([1, 12, 1, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 4 | run_i: 1 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 4 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 4 | run_i: 1 | - kv_same: True\n",
      "layer_num: 4 | run_i: 1 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 4 | run_i: 1 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 4 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 1, 3])\n",
      "layer_num: 4 | run_i: 1 | dump is not none\n",
      "layer_num: 4 | run_i: 1 | w_sizetorch.Size([1, 12, 1, 3])\n",
      "layer_num: 4 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 5 | run_i: 0 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 5 | run_i: 0 | - k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 5 | run_i: 0 | - v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 5 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 5 | run_i: 0 | - kv_same: True\n",
      "layer_num: 5 | run_i: 0 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 5 | run_i: 0 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 5 | run_i: 0 | + k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 5 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 5 | run_i: 0 | + v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 5 | run_i: 0 | = v_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 5 | run_i: 0 | _attn | v size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 1, 1])\n",
      "layer_num: 5 | run_i: 0 | dump is not none\n",
      "layer_num: 5 | run_i: 0 | w_sizetorch.Size([1, 12, 1, 1])\n",
      "layer_num: 5 | run_i: 0 | v_sizetorch.Size([1, 12, 1, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 5 | run_i: 1 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 5 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 5 | run_i: 1 | - kv_same: True\n",
      "layer_num: 5 | run_i: 1 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 5 | run_i: 1 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 5 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 1, 3])\n",
      "layer_num: 5 | run_i: 1 | dump is not none\n",
      "layer_num: 5 | run_i: 1 | w_sizetorch.Size([1, 12, 1, 3])\n",
      "layer_num: 5 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 6 | run_i: 0 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 6 | run_i: 0 | - k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 6 | run_i: 0 | - v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 6 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 6 | run_i: 0 | - kv_same: True\n",
      "layer_num: 6 | run_i: 0 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 6 | run_i: 0 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 6 | run_i: 0 | + k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 6 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 6 | run_i: 0 | + v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 6 | run_i: 0 | = v_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 6 | run_i: 0 | _attn | v size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 1, 1])\n",
      "layer_num: 6 | run_i: 0 | dump is not none\n",
      "layer_num: 6 | run_i: 0 | w_sizetorch.Size([1, 12, 1, 1])\n",
      "layer_num: 6 | run_i: 0 | v_sizetorch.Size([1, 12, 1, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 6 | run_i: 1 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 6 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 6 | run_i: 1 | - kv_same: True\n",
      "layer_num: 6 | run_i: 1 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 6 | run_i: 1 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 6 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 1, 3])\n",
      "layer_num: 6 | run_i: 1 | dump is not none\n",
      "layer_num: 6 | run_i: 1 | w_sizetorch.Size([1, 12, 1, 3])\n",
      "layer_num: 6 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 7 | run_i: 0 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 7 | run_i: 0 | - k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 7 | run_i: 0 | - v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 7 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 7 | run_i: 0 | - kv_same: True\n",
      "layer_num: 7 | run_i: 0 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 7 | run_i: 0 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 7 | run_i: 0 | + k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 7 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 7 | run_i: 0 | + v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 7 | run_i: 0 | = v_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 7 | run_i: 0 | _attn | v size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 1, 1])\n",
      "layer_num: 7 | run_i: 0 | dump is not none\n",
      "layer_num: 7 | run_i: 0 | w_sizetorch.Size([1, 12, 1, 1])\n",
      "layer_num: 7 | run_i: 0 | v_sizetorch.Size([1, 12, 1, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 7 | run_i: 1 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 7 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 7 | run_i: 1 | - kv_same: True\n",
      "layer_num: 7 | run_i: 1 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 7 | run_i: 1 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 7 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 1, 3])\n",
      "layer_num: 7 | run_i: 1 | dump is not none\n",
      "layer_num: 7 | run_i: 1 | w_sizetorch.Size([1, 12, 1, 3])\n",
      "layer_num: 7 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 8 | run_i: 0 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 8 | run_i: 0 | - k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 8 | run_i: 0 | - v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 8 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 8 | run_i: 0 | - kv_same: True\n",
      "layer_num: 8 | run_i: 0 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 8 | run_i: 0 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 8 | run_i: 0 | + k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 8 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 8 | run_i: 0 | + v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 8 | run_i: 0 | = v_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 8 | run_i: 0 | _attn | v size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 1, 1])\n",
      "layer_num: 8 | run_i: 0 | dump is not none\n",
      "layer_num: 8 | run_i: 0 | w_sizetorch.Size([1, 12, 1, 1])\n",
      "layer_num: 8 | run_i: 0 | v_sizetorch.Size([1, 12, 1, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 8 | run_i: 1 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 8 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 8 | run_i: 1 | - kv_same: True\n",
      "layer_num: 8 | run_i: 1 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 8 | run_i: 1 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 8 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 1, 3])\n",
      "layer_num: 8 | run_i: 1 | dump is not none\n",
      "layer_num: 8 | run_i: 1 | w_sizetorch.Size([1, 12, 1, 3])\n",
      "layer_num: 8 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 9 | run_i: 0 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 9 | run_i: 0 | - k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 9 | run_i: 0 | - v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 9 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 9 | run_i: 0 | - kv_same: True\n",
      "layer_num: 9 | run_i: 0 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 9 | run_i: 0 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 9 | run_i: 0 | + k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 9 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 9 | run_i: 0 | + v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 9 | run_i: 0 | = v_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 9 | run_i: 0 | _attn | v size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 1, 1])\n",
      "layer_num: 9 | run_i: 0 | dump is not none\n",
      "layer_num: 9 | run_i: 0 | w_sizetorch.Size([1, 12, 1, 1])\n",
      "layer_num: 9 | run_i: 0 | v_sizetorch.Size([1, 12, 1, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 9 | run_i: 1 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 9 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 9 | run_i: 1 | - kv_same: True\n",
      "layer_num: 9 | run_i: 1 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 9 | run_i: 1 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 9 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 1, 3])\n",
      "layer_num: 9 | run_i: 1 | dump is not none\n",
      "layer_num: 9 | run_i: 1 | w_sizetorch.Size([1, 12, 1, 3])\n",
      "layer_num: 9 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 10 | run_i: 0 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 10 | run_i: 0 | - k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 10 | run_i: 0 | - v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 10 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 10 | run_i: 0 | - kv_same: True\n",
      "layer_num: 10 | run_i: 0 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 10 | run_i: 0 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 10 | run_i: 0 | + k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 10 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 10 | run_i: 0 | + v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 10 | run_i: 0 | = v_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 10 | run_i: 0 | _attn | v size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 1, 1])\n",
      "layer_num: 10 | run_i: 0 | dump is not none\n",
      "layer_num: 10 | run_i: 0 | w_sizetorch.Size([1, 12, 1, 1])\n",
      "layer_num: 10 | run_i: 0 | v_sizetorch.Size([1, 12, 1, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 10 | run_i: 1 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 10 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 10 | run_i: 1 | - kv_same: True\n",
      "layer_num: 10 | run_i: 1 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 10 | run_i: 1 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 10 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 1, 3])\n",
      "layer_num: 10 | run_i: 1 | dump is not none\n",
      "layer_num: 10 | run_i: 1 | w_sizetorch.Size([1, 12, 1, 3])\n",
      "layer_num: 10 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 11 | run_i: 0 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 11 | run_i: 0 | - k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 11 | run_i: 0 | - v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 11 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 11 | run_i: 0 | - kv_same: True\n",
      "layer_num: 11 | run_i: 0 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 11 | run_i: 0 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 11 | run_i: 0 | + k_size: torch.Size([1, 1, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 11 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 11 | run_i: 0 | + v_size: torch.Size([1, 1, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 11 | run_i: 0 | = v_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 1])\n",
      "layer_num: 11 | run_i: 0 | _attn | v size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 1, 1])\n",
      "layer_num: 11 | run_i: 0 | dump is not none\n",
      "layer_num: 11 | run_i: 0 | w_sizetorch.Size([1, 12, 1, 1])\n",
      "layer_num: 11 | run_i: 0 | v_sizetorch.Size([1, 12, 1, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 11 | run_i: 1 | - q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 11 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 11 | run_i: 1 | - kv_same: True\n",
      "layer_num: 11 | run_i: 1 | + q_size: torch.Size([1, 1, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 1, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 1, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 11 | run_i: 1 | = q_size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 11 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | q size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 1, 3])\n",
      "layer_num: 11 | run_i: 1 | dump is not none\n",
      "layer_num: 11 | run_i: 1 | w_sizetorch.Size([1, 12, 1, 3])\n",
      "layer_num: 11 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 1, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 1, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 1, 768])\n",
      "layer_num: 0 | run_i: 0 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 0 | run_i: 0 | - k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 0 | run_i: 0 | - v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 0 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 0 | run_i: 0 | - kv_same: True\n",
      "layer_num: 0 | run_i: 0 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 0 | run_i: 0 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 0 | run_i: 0 | + k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 0 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 0 | run_i: 0 | + v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 0 | run_i: 0 | = v_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 0 | run_i: 0 | _attn | v size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 2, 2])\n",
      "layer_num: 0 | run_i: 0 | dump is not none\n",
      "layer_num: 0 | run_i: 0 | w_sizetorch.Size([1, 12, 2, 2])\n",
      "layer_num: 0 | run_i: 0 | v_sizetorch.Size([1, 12, 2, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 0 | run_i: 1 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 0 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 0 | run_i: 1 | - kv_same: True\n",
      "layer_num: 0 | run_i: 1 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 0 | run_i: 1 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 0 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 2, 3])\n",
      "layer_num: 0 | run_i: 1 | dump is not none\n",
      "layer_num: 0 | run_i: 1 | w_sizetorch.Size([1, 12, 2, 3])\n",
      "layer_num: 0 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 1 | run_i: 0 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 1 | run_i: 0 | - k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 1 | run_i: 0 | - v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 1 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 1 | run_i: 0 | - kv_same: True\n",
      "layer_num: 1 | run_i: 0 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 1 | run_i: 0 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 1 | run_i: 0 | + k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 1 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 1 | run_i: 0 | + v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 1 | run_i: 0 | = v_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 1 | run_i: 0 | _attn | v size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 2, 2])\n",
      "layer_num: 1 | run_i: 0 | dump is not none\n",
      "layer_num: 1 | run_i: 0 | w_sizetorch.Size([1, 12, 2, 2])\n",
      "layer_num: 1 | run_i: 0 | v_sizetorch.Size([1, 12, 2, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 1 | run_i: 1 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 1 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 1 | run_i: 1 | - kv_same: True\n",
      "layer_num: 1 | run_i: 1 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 1 | run_i: 1 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 1 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 2, 3])\n",
      "layer_num: 1 | run_i: 1 | dump is not none\n",
      "layer_num: 1 | run_i: 1 | w_sizetorch.Size([1, 12, 2, 3])\n",
      "layer_num: 1 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 2 | run_i: 0 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 2 | run_i: 0 | - k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 2 | run_i: 0 | - v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 2 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 2 | run_i: 0 | - kv_same: True\n",
      "layer_num: 2 | run_i: 0 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 2 | run_i: 0 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 2 | run_i: 0 | + k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 2 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 2 | run_i: 0 | + v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 2 | run_i: 0 | = v_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 2 | run_i: 0 | _attn | v size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 2, 2])\n",
      "layer_num: 2 | run_i: 0 | dump is not none\n",
      "layer_num: 2 | run_i: 0 | w_sizetorch.Size([1, 12, 2, 2])\n",
      "layer_num: 2 | run_i: 0 | v_sizetorch.Size([1, 12, 2, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 2 | run_i: 1 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 2 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 2 | run_i: 1 | - kv_same: True\n",
      "layer_num: 2 | run_i: 1 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 2 | run_i: 1 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 2 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_num: 2 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 2, 3])\n",
      "layer_num: 2 | run_i: 1 | dump is not none\n",
      "layer_num: 2 | run_i: 1 | w_sizetorch.Size([1, 12, 2, 3])\n",
      "layer_num: 2 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 3 | run_i: 0 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 3 | run_i: 0 | - k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 3 | run_i: 0 | - v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 3 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 3 | run_i: 0 | - kv_same: True\n",
      "layer_num: 3 | run_i: 0 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 3 | run_i: 0 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 3 | run_i: 0 | + k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 3 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 3 | run_i: 0 | + v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 3 | run_i: 0 | = v_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 3 | run_i: 0 | _attn | v size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 2, 2])\n",
      "layer_num: 3 | run_i: 0 | dump is not none\n",
      "layer_num: 3 | run_i: 0 | w_sizetorch.Size([1, 12, 2, 2])\n",
      "layer_num: 3 | run_i: 0 | v_sizetorch.Size([1, 12, 2, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 3 | run_i: 1 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 3 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 3 | run_i: 1 | - kv_same: True\n",
      "layer_num: 3 | run_i: 1 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 3 | run_i: 1 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 3 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 2, 3])\n",
      "layer_num: 3 | run_i: 1 | dump is not none\n",
      "layer_num: 3 | run_i: 1 | w_sizetorch.Size([1, 12, 2, 3])\n",
      "layer_num: 3 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 4 | run_i: 0 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 4 | run_i: 0 | - k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 4 | run_i: 0 | - v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 4 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 4 | run_i: 0 | - kv_same: True\n",
      "layer_num: 4 | run_i: 0 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 4 | run_i: 0 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 4 | run_i: 0 | + k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 4 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 4 | run_i: 0 | + v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 4 | run_i: 0 | = v_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 4 | run_i: 0 | _attn | v size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 2, 2])\n",
      "layer_num: 4 | run_i: 0 | dump is not none\n",
      "layer_num: 4 | run_i: 0 | w_sizetorch.Size([1, 12, 2, 2])\n",
      "layer_num: 4 | run_i: 0 | v_sizetorch.Size([1, 12, 2, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 4 | run_i: 1 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 4 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 4 | run_i: 1 | - kv_same: True\n",
      "layer_num: 4 | run_i: 1 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 4 | run_i: 1 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 4 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 2, 3])\n",
      "layer_num: 4 | run_i: 1 | dump is not none\n",
      "layer_num: 4 | run_i: 1 | w_sizetorch.Size([1, 12, 2, 3])\n",
      "layer_num: 4 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 5 | run_i: 0 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 5 | run_i: 0 | - k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 5 | run_i: 0 | - v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 5 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 5 | run_i: 0 | - kv_same: True\n",
      "layer_num: 5 | run_i: 0 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 5 | run_i: 0 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 5 | run_i: 0 | + k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 5 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 5 | run_i: 0 | + v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 5 | run_i: 0 | = v_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 5 | run_i: 0 | _attn | v size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 2, 2])\n",
      "layer_num: 5 | run_i: 0 | dump is not none\n",
      "layer_num: 5 | run_i: 0 | w_sizetorch.Size([1, 12, 2, 2])\n",
      "layer_num: 5 | run_i: 0 | v_sizetorch.Size([1, 12, 2, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 5 | run_i: 1 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 5 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 5 | run_i: 1 | - kv_same: True\n",
      "layer_num: 5 | run_i: 1 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 5 | run_i: 1 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 5 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 2, 3])\n",
      "layer_num: 5 | run_i: 1 | dump is not none\n",
      "layer_num: 5 | run_i: 1 | w_sizetorch.Size([1, 12, 2, 3])\n",
      "layer_num: 5 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 6 | run_i: 0 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 6 | run_i: 0 | - k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 6 | run_i: 0 | - v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 6 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 6 | run_i: 0 | - kv_same: True\n",
      "layer_num: 6 | run_i: 0 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 6 | run_i: 0 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 6 | run_i: 0 | + k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 6 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 6 | run_i: 0 | + v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 6 | run_i: 0 | = v_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 6 | run_i: 0 | _attn | v size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 2, 2])\n",
      "layer_num: 6 | run_i: 0 | dump is not none\n",
      "layer_num: 6 | run_i: 0 | w_sizetorch.Size([1, 12, 2, 2])\n",
      "layer_num: 6 | run_i: 0 | v_sizetorch.Size([1, 12, 2, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 6 | run_i: 1 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 6 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 6 | run_i: 1 | - kv_same: True\n",
      "layer_num: 6 | run_i: 1 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 6 | run_i: 1 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 6 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 2, 3])\n",
      "layer_num: 6 | run_i: 1 | dump is not none\n",
      "layer_num: 6 | run_i: 1 | w_sizetorch.Size([1, 12, 2, 3])\n",
      "layer_num: 6 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 7 | run_i: 0 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 7 | run_i: 0 | - k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 7 | run_i: 0 | - v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 7 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 7 | run_i: 0 | - kv_same: True\n",
      "layer_num: 7 | run_i: 0 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 7 | run_i: 0 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 7 | run_i: 0 | + k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 7 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 7 | run_i: 0 | + v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 7 | run_i: 0 | = v_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 7 | run_i: 0 | _attn | v size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 2, 2])\n",
      "layer_num: 7 | run_i: 0 | dump is not none\n",
      "layer_num: 7 | run_i: 0 | w_sizetorch.Size([1, 12, 2, 2])\n",
      "layer_num: 7 | run_i: 0 | v_sizetorch.Size([1, 12, 2, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 7 | run_i: 1 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 7 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 7 | run_i: 1 | - kv_same: True\n",
      "layer_num: 7 | run_i: 1 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 7 | run_i: 1 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 7 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 2, 3])\n",
      "layer_num: 7 | run_i: 1 | dump is not none\n",
      "layer_num: 7 | run_i: 1 | w_sizetorch.Size([1, 12, 2, 3])\n",
      "layer_num: 7 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 8 | run_i: 0 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 8 | run_i: 0 | - k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 8 | run_i: 0 | - v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 8 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 8 | run_i: 0 | - kv_same: True\n",
      "layer_num: 8 | run_i: 0 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 8 | run_i: 0 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 8 | run_i: 0 | + k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 8 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 8 | run_i: 0 | + v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 8 | run_i: 0 | = v_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 8 | run_i: 0 | _attn | v size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 2, 2])\n",
      "layer_num: 8 | run_i: 0 | dump is not none\n",
      "layer_num: 8 | run_i: 0 | w_sizetorch.Size([1, 12, 2, 2])\n",
      "layer_num: 8 | run_i: 0 | v_sizetorch.Size([1, 12, 2, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 8 | run_i: 1 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 8 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 8 | run_i: 1 | - kv_same: True\n",
      "layer_num: 8 | run_i: 1 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 8 | run_i: 1 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 8 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 2, 3])\n",
      "layer_num: 8 | run_i: 1 | dump is not none\n",
      "layer_num: 8 | run_i: 1 | w_sizetorch.Size([1, 12, 2, 3])\n",
      "layer_num: 8 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 9 | run_i: 0 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 9 | run_i: 0 | - k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 9 | run_i: 0 | - v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 9 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 9 | run_i: 0 | - kv_same: True\n",
      "layer_num: 9 | run_i: 0 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 9 | run_i: 0 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 9 | run_i: 0 | + k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 9 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 9 | run_i: 0 | + v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 9 | run_i: 0 | = v_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 9 | run_i: 0 | _attn | v size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 2, 2])\n",
      "layer_num: 9 | run_i: 0 | dump is not none\n",
      "layer_num: 9 | run_i: 0 | w_sizetorch.Size([1, 12, 2, 2])\n",
      "layer_num: 9 | run_i: 0 | v_sizetorch.Size([1, 12, 2, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 9 | run_i: 1 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 9 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 9 | run_i: 1 | - kv_same: True\n",
      "layer_num: 9 | run_i: 1 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 9 | run_i: 1 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 9 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 2, 3])\n",
      "layer_num: 9 | run_i: 1 | dump is not none\n",
      "layer_num: 9 | run_i: 1 | w_sizetorch.Size([1, 12, 2, 3])\n",
      "layer_num: 9 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 10 | run_i: 0 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 10 | run_i: 0 | - k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 10 | run_i: 0 | - v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 10 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 10 | run_i: 0 | - kv_same: True\n",
      "layer_num: 10 | run_i: 0 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 10 | run_i: 0 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 10 | run_i: 0 | + k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 10 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 10 | run_i: 0 | + v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 10 | run_i: 0 | = v_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 10 | run_i: 0 | _attn | v size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 2, 2])\n",
      "layer_num: 10 | run_i: 0 | dump is not none\n",
      "layer_num: 10 | run_i: 0 | w_sizetorch.Size([1, 12, 2, 2])\n",
      "layer_num: 10 | run_i: 0 | v_sizetorch.Size([1, 12, 2, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 10 | run_i: 1 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 10 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 10 | run_i: 1 | - kv_same: True\n",
      "layer_num: 10 | run_i: 1 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 10 | run_i: 1 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 10 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 2, 3])\n",
      "layer_num: 10 | run_i: 1 | dump is not none\n",
      "layer_num: 10 | run_i: 1 | w_sizetorch.Size([1, 12, 2, 3])\n",
      "layer_num: 10 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 11 | run_i: 0 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 11 | run_i: 0 | - k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 11 | run_i: 0 | - v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 11 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 11 | run_i: 0 | - kv_same: True\n",
      "layer_num: 11 | run_i: 0 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 11 | run_i: 0 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 11 | run_i: 0 | + k_size: torch.Size([1, 2, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 11 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 11 | run_i: 0 | + v_size: torch.Size([1, 2, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 11 | run_i: 0 | = v_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 2])\n",
      "layer_num: 11 | run_i: 0 | _attn | v size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 2, 2])\n",
      "layer_num: 11 | run_i: 0 | dump is not none\n",
      "layer_num: 11 | run_i: 0 | w_sizetorch.Size([1, 12, 2, 2])\n",
      "layer_num: 11 | run_i: 0 | v_sizetorch.Size([1, 12, 2, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 11 | run_i: 1 | - q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 11 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 11 | run_i: 1 | - kv_same: True\n",
      "layer_num: 11 | run_i: 1 | + q_size: torch.Size([1, 2, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 2, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 2, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 11 | run_i: 1 | = q_size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 11 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | q size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 2, 3])\n",
      "layer_num: 11 | run_i: 1 | dump is not none\n",
      "layer_num: 11 | run_i: 1 | w_sizetorch.Size([1, 12, 2, 3])\n",
      "layer_num: 11 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 2, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 2, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 2, 768])\n",
      "layer_num: 0 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 0 | run_i: 0 | - kv_same: True\n",
      "layer_num: 0 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 0 | run_i: 0 | dump is not none\n",
      "layer_num: 0 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 0 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 0 | run_i: 1 | - kv_same: True\n",
      "layer_num: 0 | run_i: 1 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 0 | run_i: 1 | dump is not none\n",
      "layer_num: 0 | run_i: 1 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 0 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 1 | run_i: 0 | - kv_same: True\n",
      "layer_num: 1 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 1 | run_i: 0 | dump is not none\n",
      "layer_num: 1 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 1 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 1 | run_i: 1 | - kv_same: True\n",
      "layer_num: 1 | run_i: 1 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 1 | run_i: 1 | dump is not none\n",
      "layer_num: 1 | run_i: 1 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 1 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 2 | run_i: 0 | - kv_same: True\n",
      "layer_num: 2 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 2 | run_i: 0 | dump is not none\n",
      "layer_num: 2 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 2 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 2 | run_i: 1 | - kv_same: True\n",
      "layer_num: 2 | run_i: 1 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 2 | run_i: 1 | dump is not none\n",
      "layer_num: 2 | run_i: 1 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 2 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 3 | run_i: 0 | - kv_same: True\n",
      "layer_num: 3 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 3 | run_i: 0 | dump is not none\n",
      "layer_num: 3 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 3 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 3 | run_i: 1 | - kv_same: True\n",
      "layer_num: 3 | run_i: 1 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 3 | run_i: 1 | dump is not none\n",
      "layer_num: 3 | run_i: 1 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 3 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 4 | run_i: 0 | - kv_same: True\n",
      "layer_num: 4 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 4 | run_i: 0 | dump is not none\n",
      "layer_num: 4 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 4 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 4 | run_i: 1 | - kv_same: True\n",
      "layer_num: 4 | run_i: 1 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 4 | run_i: 1 | dump is not none\n",
      "layer_num: 4 | run_i: 1 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 4 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 5 | run_i: 0 | - kv_same: True\n",
      "layer_num: 5 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 5 | run_i: 0 | dump is not none\n",
      "layer_num: 5 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 5 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 5 | run_i: 1 | - kv_same: True\n",
      "layer_num: 5 | run_i: 1 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 5 | run_i: 1 | dump is not none\n",
      "layer_num: 5 | run_i: 1 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 5 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 6 | run_i: 0 | - kv_same: True\n",
      "layer_num: 6 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 6 | run_i: 0 | dump is not none\n",
      "layer_num: 6 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 6 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 6 | run_i: 1 | - kv_same: True\n",
      "layer_num: 6 | run_i: 1 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 6 | run_i: 1 | dump is not none\n",
      "layer_num: 6 | run_i: 1 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 6 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 7 | run_i: 0 | - kv_same: True\n",
      "layer_num: 7 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 7 | run_i: 0 | dump is not none\n",
      "layer_num: 7 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 7 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 7 | run_i: 1 | - kv_same: True\n",
      "layer_num: 7 | run_i: 1 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 7 | run_i: 1 | dump is not none\n",
      "layer_num: 7 | run_i: 1 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 7 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 8 | run_i: 0 | - kv_same: True\n",
      "layer_num: 8 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 8 | run_i: 0 | dump is not none\n",
      "layer_num: 8 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 8 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 8 | run_i: 1 | - kv_same: True\n",
      "layer_num: 8 | run_i: 1 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 8 | run_i: 1 | dump is not none\n",
      "layer_num: 8 | run_i: 1 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 8 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 9 | run_i: 0 | - kv_same: True\n",
      "layer_num: 9 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 9 | run_i: 0 | dump is not none\n",
      "layer_num: 9 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 9 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 9 | run_i: 1 | - kv_same: True\n",
      "layer_num: 9 | run_i: 1 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 9 | run_i: 1 | dump is not none\n",
      "layer_num: 9 | run_i: 1 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 9 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 10 | run_i: 0 | - kv_same: True\n",
      "layer_num: 10 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 10 | run_i: 0 | dump is not none\n",
      "layer_num: 10 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 10 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 10 | run_i: 1 | - kv_same: True\n",
      "layer_num: 10 | run_i: 1 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 10 | run_i: 1 | dump is not none\n",
      "layer_num: 10 | run_i: 1 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 10 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 11 | run_i: 0 | - kv_same: True\n",
      "layer_num: 11 | run_i: 0 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 0 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 0 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 0 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 0 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 0 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 11 | run_i: 0 | dump is not none\n",
      "layer_num: 11 | run_i: 0 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 11 | run_i: 0 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | - q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 11 | run_i: 1 | - kv_same: True\n",
      "layer_num: 11 | run_i: 1 | + q_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | = q_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | q size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 3, 3])\n",
      "layer_num: 11 | run_i: 1 | dump is not none\n",
      "layer_num: 11 | run_i: 1 | w_sizetorch.Size([1, 12, 3, 3])\n",
      "layer_num: 11 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 0 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 0 | run_i: 0 | - k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 0 | run_i: 0 | - v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 0 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 0 | run_i: 0 | - kv_same: True\n",
      "layer_num: 0 | run_i: 0 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 0 | run_i: 0 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 0 | run_i: 0 | + k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 0 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 0 | run_i: 0 | + v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 0 | run_i: 0 | = v_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 0 | run_i: 0 | _attn | v size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 4, 4])\n",
      "layer_num: 0 | run_i: 0 | dump is not none\n",
      "layer_num: 0 | run_i: 0 | w_sizetorch.Size([1, 12, 4, 4])\n",
      "layer_num: 0 | run_i: 0 | v_sizetorch.Size([1, 12, 4, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 0 | run_i: 1 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 0 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 0 | run_i: 1 | - kv_same: True\n",
      "layer_num: 0 | run_i: 1 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 0 | run_i: 1 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 0 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 4, 3])\n",
      "layer_num: 0 | run_i: 1 | dump is not none\n",
      "layer_num: 0 | run_i: 1 | w_sizetorch.Size([1, 12, 4, 3])\n",
      "layer_num: 0 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 1 | run_i: 0 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 1 | run_i: 0 | - k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 1 | run_i: 0 | - v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 1 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 1 | run_i: 0 | - kv_same: True\n",
      "layer_num: 1 | run_i: 0 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 1 | run_i: 0 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 1 | run_i: 0 | + k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 1 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 1 | run_i: 0 | + v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 1 | run_i: 0 | = v_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 1 | run_i: 0 | _attn | v size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 4, 4])\n",
      "layer_num: 1 | run_i: 0 | dump is not none\n",
      "layer_num: 1 | run_i: 0 | w_sizetorch.Size([1, 12, 4, 4])\n",
      "layer_num: 1 | run_i: 0 | v_sizetorch.Size([1, 12, 4, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 1 | run_i: 1 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 1 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 1 | run_i: 1 | - kv_same: True\n",
      "layer_num: 1 | run_i: 1 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 1 | run_i: 1 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 1 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 4, 3])\n",
      "layer_num: 1 | run_i: 1 | dump is not none\n",
      "layer_num: 1 | run_i: 1 | w_sizetorch.Size([1, 12, 4, 3])\n",
      "layer_num: 1 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 2 | run_i: 0 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 2 | run_i: 0 | - k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 2 | run_i: 0 | - v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 2 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 2 | run_i: 0 | - kv_same: True\n",
      "layer_num: 2 | run_i: 0 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 2 | run_i: 0 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 2 | run_i: 0 | + k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 2 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 2 | run_i: 0 | + v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 2 | run_i: 0 | = v_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 2 | run_i: 0 | _attn | v size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 4, 4])\n",
      "layer_num: 2 | run_i: 0 | dump is not none\n",
      "layer_num: 2 | run_i: 0 | w_sizetorch.Size([1, 12, 4, 4])\n",
      "layer_num: 2 | run_i: 0 | v_sizetorch.Size([1, 12, 4, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 2 | run_i: 1 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 2 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 2 | run_i: 1 | - kv_same: True\n",
      "layer_num: 2 | run_i: 1 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 2 | run_i: 1 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 2 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 4, 3])\n",
      "layer_num: 2 | run_i: 1 | dump is not none\n",
      "layer_num: 2 | run_i: 1 | w_sizetorch.Size([1, 12, 4, 3])\n",
      "layer_num: 2 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 3 | run_i: 0 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 3 | run_i: 0 | - k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 3 | run_i: 0 | - v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 3 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 3 | run_i: 0 | - kv_same: True\n",
      "layer_num: 3 | run_i: 0 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 3 | run_i: 0 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 3 | run_i: 0 | + k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 3 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 3 | run_i: 0 | + v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 3 | run_i: 0 | = v_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 3 | run_i: 0 | _attn | v size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 4, 4])\n",
      "layer_num: 3 | run_i: 0 | dump is not none\n",
      "layer_num: 3 | run_i: 0 | w_sizetorch.Size([1, 12, 4, 4])\n",
      "layer_num: 3 | run_i: 0 | v_sizetorch.Size([1, 12, 4, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 3 | run_i: 1 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 3 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 3 | run_i: 1 | - kv_same: True\n",
      "layer_num: 3 | run_i: 1 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 3 | run_i: 1 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 3 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 4, 3])\n",
      "layer_num: 3 | run_i: 1 | dump is not none\n",
      "layer_num: 3 | run_i: 1 | w_sizetorch.Size([1, 12, 4, 3])\n",
      "layer_num: 3 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 4 | run_i: 0 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 4 | run_i: 0 | - k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 4 | run_i: 0 | - v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 4 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 4 | run_i: 0 | - kv_same: True\n",
      "layer_num: 4 | run_i: 0 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 4 | run_i: 0 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 4 | run_i: 0 | + k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 4 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 4 | run_i: 0 | + v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 4 | run_i: 0 | = v_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 4 | run_i: 0 | _attn | v size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 4, 4])\n",
      "layer_num: 4 | run_i: 0 | dump is not none\n",
      "layer_num: 4 | run_i: 0 | w_sizetorch.Size([1, 12, 4, 4])\n",
      "layer_num: 4 | run_i: 0 | v_sizetorch.Size([1, 12, 4, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 4 | run_i: 1 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 4 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 4 | run_i: 1 | - kv_same: True\n",
      "layer_num: 4 | run_i: 1 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 4 | run_i: 1 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 4 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 4, 3])\n",
      "layer_num: 4 | run_i: 1 | dump is not none\n",
      "layer_num: 4 | run_i: 1 | w_sizetorch.Size([1, 12, 4, 3])\n",
      "layer_num: 4 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 5 | run_i: 0 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 5 | run_i: 0 | - k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 5 | run_i: 0 | - v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 5 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 5 | run_i: 0 | - kv_same: True\n",
      "layer_num: 5 | run_i: 0 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 5 | run_i: 0 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 5 | run_i: 0 | + k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 5 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 5 | run_i: 0 | + v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 5 | run_i: 0 | = v_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 5 | run_i: 0 | _attn | v size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 4, 4])\n",
      "layer_num: 5 | run_i: 0 | dump is not none\n",
      "layer_num: 5 | run_i: 0 | w_sizetorch.Size([1, 12, 4, 4])\n",
      "layer_num: 5 | run_i: 0 | v_sizetorch.Size([1, 12, 4, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 5 | run_i: 1 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 5 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 5 | run_i: 1 | - kv_same: True\n",
      "layer_num: 5 | run_i: 1 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 5 | run_i: 1 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 5 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 4, 3])\n",
      "layer_num: 5 | run_i: 1 | dump is not none\n",
      "layer_num: 5 | run_i: 1 | w_sizetorch.Size([1, 12, 4, 3])\n",
      "layer_num: 5 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 6 | run_i: 0 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 6 | run_i: 0 | - k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 6 | run_i: 0 | - v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 6 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 6 | run_i: 0 | - kv_same: True\n",
      "layer_num: 6 | run_i: 0 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 6 | run_i: 0 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 6 | run_i: 0 | + k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 6 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 6 | run_i: 0 | + v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 6 | run_i: 0 | = v_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 6 | run_i: 0 | _attn | v size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 4, 4])\n",
      "layer_num: 6 | run_i: 0 | dump is not none\n",
      "layer_num: 6 | run_i: 0 | w_sizetorch.Size([1, 12, 4, 4])\n",
      "layer_num: 6 | run_i: 0 | v_sizetorch.Size([1, 12, 4, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 6 | run_i: 1 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 6 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 6 | run_i: 1 | - kv_same: True\n",
      "layer_num: 6 | run_i: 1 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 6 | run_i: 1 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 6 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 4, 3])\n",
      "layer_num: 6 | run_i: 1 | dump is not none\n",
      "layer_num: 6 | run_i: 1 | w_sizetorch.Size([1, 12, 4, 3])\n",
      "layer_num: 6 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 7 | run_i: 0 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 7 | run_i: 0 | - k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 7 | run_i: 0 | - v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 7 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 7 | run_i: 0 | - kv_same: True\n",
      "layer_num: 7 | run_i: 0 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 7 | run_i: 0 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 7 | run_i: 0 | + k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 7 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 7 | run_i: 0 | + v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 7 | run_i: 0 | = v_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 7 | run_i: 0 | _attn | v size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 4, 4])\n",
      "layer_num: 7 | run_i: 0 | dump is not none\n",
      "layer_num: 7 | run_i: 0 | w_sizetorch.Size([1, 12, 4, 4])\n",
      "layer_num: 7 | run_i: 0 | v_sizetorch.Size([1, 12, 4, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 7 | run_i: 1 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 7 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 7 | run_i: 1 | - kv_same: True\n",
      "layer_num: 7 | run_i: 1 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 7 | run_i: 1 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 7 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 4, 3])\n",
      "layer_num: 7 | run_i: 1 | dump is not none\n",
      "layer_num: 7 | run_i: 1 | w_sizetorch.Size([1, 12, 4, 3])\n",
      "layer_num: 7 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 8 | run_i: 0 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 8 | run_i: 0 | - k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 8 | run_i: 0 | - v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 8 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 8 | run_i: 0 | - kv_same: True\n",
      "layer_num: 8 | run_i: 0 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 8 | run_i: 0 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 8 | run_i: 0 | + k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 8 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 8 | run_i: 0 | + v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 8 | run_i: 0 | = v_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 8 | run_i: 0 | _attn | v size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 4, 4])\n",
      "layer_num: 8 | run_i: 0 | dump is not none\n",
      "layer_num: 8 | run_i: 0 | w_sizetorch.Size([1, 12, 4, 4])\n",
      "layer_num: 8 | run_i: 0 | v_sizetorch.Size([1, 12, 4, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 8 | run_i: 1 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 8 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 8 | run_i: 1 | - kv_same: True\n",
      "layer_num: 8 | run_i: 1 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 8 | run_i: 1 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 8 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 4, 3])\n",
      "layer_num: 8 | run_i: 1 | dump is not none\n",
      "layer_num: 8 | run_i: 1 | w_sizetorch.Size([1, 12, 4, 3])\n",
      "layer_num: 8 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 9 | run_i: 0 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 9 | run_i: 0 | - k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 9 | run_i: 0 | - v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 9 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 9 | run_i: 0 | - kv_same: True\n",
      "layer_num: 9 | run_i: 0 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 9 | run_i: 0 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 9 | run_i: 0 | + k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 9 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 9 | run_i: 0 | + v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 9 | run_i: 0 | = v_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 9 | run_i: 0 | _attn | v size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 4, 4])\n",
      "layer_num: 9 | run_i: 0 | dump is not none\n",
      "layer_num: 9 | run_i: 0 | w_sizetorch.Size([1, 12, 4, 4])\n",
      "layer_num: 9 | run_i: 0 | v_sizetorch.Size([1, 12, 4, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 9 | run_i: 1 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 9 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 9 | run_i: 1 | - kv_same: True\n",
      "layer_num: 9 | run_i: 1 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 9 | run_i: 1 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 9 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 4, 3])\n",
      "layer_num: 9 | run_i: 1 | dump is not none\n",
      "layer_num: 9 | run_i: 1 | w_sizetorch.Size([1, 12, 4, 3])\n",
      "layer_num: 9 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 10 | run_i: 0 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 10 | run_i: 0 | - k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 10 | run_i: 0 | - v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 10 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 10 | run_i: 0 | - kv_same: True\n",
      "layer_num: 10 | run_i: 0 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 10 | run_i: 0 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 10 | run_i: 0 | + k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 10 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 10 | run_i: 0 | + v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 10 | run_i: 0 | = v_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 10 | run_i: 0 | _attn | v size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 4, 4])\n",
      "layer_num: 10 | run_i: 0 | dump is not none\n",
      "layer_num: 10 | run_i: 0 | w_sizetorch.Size([1, 12, 4, 4])\n",
      "layer_num: 10 | run_i: 0 | v_sizetorch.Size([1, 12, 4, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 10 | run_i: 1 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 10 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 10 | run_i: 1 | - kv_same: True\n",
      "layer_num: 10 | run_i: 1 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 10 | run_i: 1 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 10 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 4, 3])\n",
      "layer_num: 10 | run_i: 1 | dump is not none\n",
      "layer_num: 10 | run_i: 1 | w_sizetorch.Size([1, 12, 4, 3])\n",
      "layer_num: 10 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 11 | run_i: 0 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 11 | run_i: 0 | - k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 11 | run_i: 0 | - v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 11 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 11 | run_i: 0 | - kv_same: True\n",
      "layer_num: 11 | run_i: 0 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 11 | run_i: 0 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 11 | run_i: 0 | + k_size: torch.Size([1, 4, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 11 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 11 | run_i: 0 | + v_size: torch.Size([1, 4, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 11 | run_i: 0 | = v_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 4])\n",
      "layer_num: 11 | run_i: 0 | _attn | v size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 4, 4])\n",
      "layer_num: 11 | run_i: 0 | dump is not none\n",
      "layer_num: 11 | run_i: 0 | w_sizetorch.Size([1, 12, 4, 4])\n",
      "layer_num: 11 | run_i: 0 | v_sizetorch.Size([1, 12, 4, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 11 | run_i: 1 | - q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 11 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 11 | run_i: 1 | - kv_same: True\n",
      "layer_num: 11 | run_i: 1 | + q_size: torch.Size([1, 4, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 4, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 4, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 11 | run_i: 1 | = q_size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 11 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | q size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 4, 3])\n",
      "layer_num: 11 | run_i: 1 | dump is not none\n",
      "layer_num: 11 | run_i: 1 | w_sizetorch.Size([1, 12, 4, 3])\n",
      "layer_num: 11 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 4, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 4, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 4, 768])\n",
      "layer_num: 0 | run_i: 0 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 0 | run_i: 0 | - k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 0 | run_i: 0 | - v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 0 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 0 | run_i: 0 | - kv_same: True\n",
      "layer_num: 0 | run_i: 0 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 0 | run_i: 0 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 0 | run_i: 0 | + k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 0 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 0 | run_i: 0 | + v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 0 | run_i: 0 | = v_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 0 | run_i: 0 | _attn | v size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 5, 5])\n",
      "layer_num: 0 | run_i: 0 | dump is not none\n",
      "layer_num: 0 | run_i: 0 | w_sizetorch.Size([1, 12, 5, 5])\n",
      "layer_num: 0 | run_i: 0 | v_sizetorch.Size([1, 12, 5, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 0 | run_i: 1 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 0 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 0 | run_i: 1 | - kv_same: True\n",
      "layer_num: 0 | run_i: 1 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 0 | run_i: 1 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 0 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 5, 3])\n",
      "layer_num: 0 | run_i: 1 | dump is not none\n",
      "layer_num: 0 | run_i: 1 | w_sizetorch.Size([1, 12, 5, 3])\n",
      "layer_num: 0 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 1 | run_i: 0 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 1 | run_i: 0 | - k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 1 | run_i: 0 | - v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 1 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 1 | run_i: 0 | - kv_same: True\n",
      "layer_num: 1 | run_i: 0 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 1 | run_i: 0 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 1 | run_i: 0 | + k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 1 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 1 | run_i: 0 | + v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 1 | run_i: 0 | = v_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 1 | run_i: 0 | _attn | v size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 5, 5])\n",
      "layer_num: 1 | run_i: 0 | dump is not none\n",
      "layer_num: 1 | run_i: 0 | w_sizetorch.Size([1, 12, 5, 5])\n",
      "layer_num: 1 | run_i: 0 | v_sizetorch.Size([1, 12, 5, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 1 | run_i: 1 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 1 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 1 | run_i: 1 | - kv_same: True\n",
      "layer_num: 1 | run_i: 1 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 1 | run_i: 1 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 1 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 5, 3])\n",
      "layer_num: 1 | run_i: 1 | dump is not none\n",
      "layer_num: 1 | run_i: 1 | w_sizetorch.Size([1, 12, 5, 3])\n",
      "layer_num: 1 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 2 | run_i: 0 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 2 | run_i: 0 | - k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 2 | run_i: 0 | - v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 2 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 2 | run_i: 0 | - kv_same: True\n",
      "layer_num: 2 | run_i: 0 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 2 | run_i: 0 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 2 | run_i: 0 | + k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 2 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 2 | run_i: 0 | + v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 2 | run_i: 0 | = v_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 2 | run_i: 0 | _attn | v size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 5, 5])\n",
      "layer_num: 2 | run_i: 0 | dump is not none\n",
      "layer_num: 2 | run_i: 0 | w_sizetorch.Size([1, 12, 5, 5])\n",
      "layer_num: 2 | run_i: 0 | v_sizetorch.Size([1, 12, 5, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 2 | run_i: 1 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 2 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 2 | run_i: 1 | - kv_same: True\n",
      "layer_num: 2 | run_i: 1 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 2 | run_i: 1 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 2 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 5, 3])\n",
      "layer_num: 2 | run_i: 1 | dump is not none\n",
      "layer_num: 2 | run_i: 1 | w_sizetorch.Size([1, 12, 5, 3])\n",
      "layer_num: 2 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 3 | run_i: 0 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 3 | run_i: 0 | - k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 3 | run_i: 0 | - v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 3 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 3 | run_i: 0 | - kv_same: True\n",
      "layer_num: 3 | run_i: 0 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 3 | run_i: 0 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 3 | run_i: 0 | + k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 3 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 3 | run_i: 0 | + v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 3 | run_i: 0 | = v_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 3 | run_i: 0 | _attn | v size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 5, 5])\n",
      "layer_num: 3 | run_i: 0 | dump is not none\n",
      "layer_num: 3 | run_i: 0 | w_sizetorch.Size([1, 12, 5, 5])\n",
      "layer_num: 3 | run_i: 0 | v_sizetorch.Size([1, 12, 5, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 3 | run_i: 1 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 3 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 3 | run_i: 1 | - kv_same: True\n",
      "layer_num: 3 | run_i: 1 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 3 | run_i: 1 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 3 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 5, 3])\n",
      "layer_num: 3 | run_i: 1 | dump is not none\n",
      "layer_num: 3 | run_i: 1 | w_sizetorch.Size([1, 12, 5, 3])\n",
      "layer_num: 3 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 4 | run_i: 0 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 4 | run_i: 0 | - k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 4 | run_i: 0 | - v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 4 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 4 | run_i: 0 | - kv_same: True\n",
      "layer_num: 4 | run_i: 0 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 4 | run_i: 0 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 4 | run_i: 0 | + k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 4 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 4 | run_i: 0 | + v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 4 | run_i: 0 | = v_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 4 | run_i: 0 | _attn | v size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 5, 5])\n",
      "layer_num: 4 | run_i: 0 | dump is not none\n",
      "layer_num: 4 | run_i: 0 | w_sizetorch.Size([1, 12, 5, 5])\n",
      "layer_num: 4 | run_i: 0 | v_sizetorch.Size([1, 12, 5, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 4 | run_i: 1 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 4 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 4 | run_i: 1 | - kv_same: True\n",
      "layer_num: 4 | run_i: 1 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 4 | run_i: 1 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 4 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 5, 3])\n",
      "layer_num: 4 | run_i: 1 | dump is not none\n",
      "layer_num: 4 | run_i: 1 | w_sizetorch.Size([1, 12, 5, 3])\n",
      "layer_num: 4 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 5 | run_i: 0 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 5 | run_i: 0 | - k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 5 | run_i: 0 | - v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 5 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 5 | run_i: 0 | - kv_same: True\n",
      "layer_num: 5 | run_i: 0 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 5 | run_i: 0 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 5 | run_i: 0 | + k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 5 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 5 | run_i: 0 | + v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 5 | run_i: 0 | = v_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 5 | run_i: 0 | _attn | v size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 5, 5])\n",
      "layer_num: 5 | run_i: 0 | dump is not none\n",
      "layer_num: 5 | run_i: 0 | w_sizetorch.Size([1, 12, 5, 5])\n",
      "layer_num: 5 | run_i: 0 | v_sizetorch.Size([1, 12, 5, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 5 | run_i: 1 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 5 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 5 | run_i: 1 | - kv_same: True\n",
      "layer_num: 5 | run_i: 1 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 5 | run_i: 1 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 5 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 5, 3])\n",
      "layer_num: 5 | run_i: 1 | dump is not none\n",
      "layer_num: 5 | run_i: 1 | w_sizetorch.Size([1, 12, 5, 3])\n",
      "layer_num: 5 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 6 | run_i: 0 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 6 | run_i: 0 | - k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 6 | run_i: 0 | - v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 6 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 6 | run_i: 0 | - kv_same: True\n",
      "layer_num: 6 | run_i: 0 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 6 | run_i: 0 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 6 | run_i: 0 | + k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 6 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 6 | run_i: 0 | + v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 6 | run_i: 0 | = v_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 6 | run_i: 0 | _attn | v size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 5, 5])\n",
      "layer_num: 6 | run_i: 0 | dump is not none\n",
      "layer_num: 6 | run_i: 0 | w_sizetorch.Size([1, 12, 5, 5])\n",
      "layer_num: 6 | run_i: 0 | v_sizetorch.Size([1, 12, 5, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 6 | run_i: 1 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 6 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 6 | run_i: 1 | - kv_same: True\n",
      "layer_num: 6 | run_i: 1 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 6 | run_i: 1 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 6 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 5, 3])\n",
      "layer_num: 6 | run_i: 1 | dump is not none\n",
      "layer_num: 6 | run_i: 1 | w_sizetorch.Size([1, 12, 5, 3])\n",
      "layer_num: 6 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 7 | run_i: 0 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 7 | run_i: 0 | - k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 7 | run_i: 0 | - v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 7 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 7 | run_i: 0 | - kv_same: True\n",
      "layer_num: 7 | run_i: 0 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 7 | run_i: 0 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 7 | run_i: 0 | + k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 7 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 7 | run_i: 0 | + v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 7 | run_i: 0 | = v_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 7 | run_i: 0 | _attn | v size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 5, 5])\n",
      "layer_num: 7 | run_i: 0 | dump is not none\n",
      "layer_num: 7 | run_i: 0 | w_sizetorch.Size([1, 12, 5, 5])\n",
      "layer_num: 7 | run_i: 0 | v_sizetorch.Size([1, 12, 5, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 7 | run_i: 1 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 7 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 7 | run_i: 1 | - kv_same: True\n",
      "layer_num: 7 | run_i: 1 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 7 | run_i: 1 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 7 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 5, 3])\n",
      "layer_num: 7 | run_i: 1 | dump is not none\n",
      "layer_num: 7 | run_i: 1 | w_sizetorch.Size([1, 12, 5, 3])\n",
      "layer_num: 7 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 8 | run_i: 0 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 8 | run_i: 0 | - k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 8 | run_i: 0 | - v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 8 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 8 | run_i: 0 | - kv_same: True\n",
      "layer_num: 8 | run_i: 0 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 8 | run_i: 0 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 8 | run_i: 0 | + k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 8 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 8 | run_i: 0 | + v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 8 | run_i: 0 | = v_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 8 | run_i: 0 | _attn | v size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 5, 5])\n",
      "layer_num: 8 | run_i: 0 | dump is not none\n",
      "layer_num: 8 | run_i: 0 | w_sizetorch.Size([1, 12, 5, 5])\n",
      "layer_num: 8 | run_i: 0 | v_sizetorch.Size([1, 12, 5, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 8 | run_i: 1 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 8 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 8 | run_i: 1 | - kv_same: True\n",
      "layer_num: 8 | run_i: 1 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 8 | run_i: 1 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 8 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 5, 3])\n",
      "layer_num: 8 | run_i: 1 | dump is not none\n",
      "layer_num: 8 | run_i: 1 | w_sizetorch.Size([1, 12, 5, 3])\n",
      "layer_num: 8 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 9 | run_i: 0 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 9 | run_i: 0 | - k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 9 | run_i: 0 | - v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 9 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 9 | run_i: 0 | - kv_same: True\n",
      "layer_num: 9 | run_i: 0 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 9 | run_i: 0 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 9 | run_i: 0 | + k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 9 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 9 | run_i: 0 | + v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 9 | run_i: 0 | = v_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 9 | run_i: 0 | _attn | v size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 5, 5])\n",
      "layer_num: 9 | run_i: 0 | dump is not none\n",
      "layer_num: 9 | run_i: 0 | w_sizetorch.Size([1, 12, 5, 5])\n",
      "layer_num: 9 | run_i: 0 | v_sizetorch.Size([1, 12, 5, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 9 | run_i: 1 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 9 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 9 | run_i: 1 | - kv_same: True\n",
      "layer_num: 9 | run_i: 1 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 9 | run_i: 1 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 9 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 5, 3])\n",
      "layer_num: 9 | run_i: 1 | dump is not none\n",
      "layer_num: 9 | run_i: 1 | w_sizetorch.Size([1, 12, 5, 3])\n",
      "layer_num: 9 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 10 | run_i: 0 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 10 | run_i: 0 | - k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 10 | run_i: 0 | - v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 10 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 10 | run_i: 0 | - kv_same: True\n",
      "layer_num: 10 | run_i: 0 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 10 | run_i: 0 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 10 | run_i: 0 | + k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 10 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 10 | run_i: 0 | + v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 10 | run_i: 0 | = v_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 10 | run_i: 0 | _attn | v size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 5, 5])\n",
      "layer_num: 10 | run_i: 0 | dump is not none\n",
      "layer_num: 10 | run_i: 0 | w_sizetorch.Size([1, 12, 5, 5])\n",
      "layer_num: 10 | run_i: 0 | v_sizetorch.Size([1, 12, 5, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 10 | run_i: 1 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 10 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 10 | run_i: 1 | - kv_same: True\n",
      "layer_num: 10 | run_i: 1 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 10 | run_i: 1 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 10 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 5, 3])\n",
      "layer_num: 10 | run_i: 1 | dump is not none\n",
      "layer_num: 10 | run_i: 1 | w_sizetorch.Size([1, 12, 5, 3])\n",
      "layer_num: 10 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 11 | run_i: 0 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 11 | run_i: 0 | - k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 11 | run_i: 0 | - v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 11 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 11 | run_i: 0 | - kv_same: True\n",
      "layer_num: 11 | run_i: 0 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 11 | run_i: 0 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 11 | run_i: 0 | + k_size: torch.Size([1, 5, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 11 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 11 | run_i: 0 | + v_size: torch.Size([1, 5, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 11 | run_i: 0 | = v_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 5])\n",
      "layer_num: 11 | run_i: 0 | _attn | v size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 5, 5])\n",
      "layer_num: 11 | run_i: 0 | dump is not none\n",
      "layer_num: 11 | run_i: 0 | w_sizetorch.Size([1, 12, 5, 5])\n",
      "layer_num: 11 | run_i: 0 | v_sizetorch.Size([1, 12, 5, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 11 | run_i: 1 | - q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 11 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 11 | run_i: 1 | - kv_same: True\n",
      "layer_num: 11 | run_i: 1 | + q_size: torch.Size([1, 5, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 5, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 5, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 11 | run_i: 1 | = q_size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 11 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | q size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 5, 3])\n",
      "layer_num: 11 | run_i: 1 | dump is not none\n",
      "layer_num: 11 | run_i: 1 | w_sizetorch.Size([1, 12, 5, 3])\n",
      "layer_num: 11 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 5, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 5, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 5, 768])\n",
      "layer_num: 0 | run_i: 0 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 0 | run_i: 0 | - k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 0 | run_i: 0 | - v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 0 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 0 | run_i: 0 | - kv_same: True\n",
      "layer_num: 0 | run_i: 0 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 0 | run_i: 0 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 0 | run_i: 0 | + k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 0 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 0 | run_i: 0 | + v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 0 | run_i: 0 | = v_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 0 | run_i: 0 | _attn | v size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 6, 6])\n",
      "layer_num: 0 | run_i: 0 | dump is not none\n",
      "layer_num: 0 | run_i: 0 | w_sizetorch.Size([1, 12, 6, 6])\n",
      "layer_num: 0 | run_i: 0 | v_sizetorch.Size([1, 12, 6, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 0 | run_i: 1 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 0 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 0 | run_i: 1 | - kv_same: True\n",
      "layer_num: 0 | run_i: 1 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 0 | run_i: 1 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 0 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 6, 3])\n",
      "layer_num: 0 | run_i: 1 | dump is not none\n",
      "layer_num: 0 | run_i: 1 | w_sizetorch.Size([1, 12, 6, 3])\n",
      "layer_num: 0 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 1 | run_i: 0 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 1 | run_i: 0 | - k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 1 | run_i: 0 | - v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 1 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 1 | run_i: 0 | - kv_same: True\n",
      "layer_num: 1 | run_i: 0 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 1 | run_i: 0 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 1 | run_i: 0 | + k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 1 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 1 | run_i: 0 | + v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 1 | run_i: 0 | = v_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 1 | run_i: 0 | _attn | v size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 6, 6])\n",
      "layer_num: 1 | run_i: 0 | dump is not none\n",
      "layer_num: 1 | run_i: 0 | w_sizetorch.Size([1, 12, 6, 6])\n",
      "layer_num: 1 | run_i: 0 | v_sizetorch.Size([1, 12, 6, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 1 | run_i: 1 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 1 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 1 | run_i: 1 | - kv_same: True\n",
      "layer_num: 1 | run_i: 1 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 1 | run_i: 1 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 1 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 6, 3])\n",
      "layer_num: 1 | run_i: 1 | dump is not none\n",
      "layer_num: 1 | run_i: 1 | w_sizetorch.Size([1, 12, 6, 3])\n",
      "layer_num: 1 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 2 | run_i: 0 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 2 | run_i: 0 | - k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 2 | run_i: 0 | - v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 2 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 2 | run_i: 0 | - kv_same: True\n",
      "layer_num: 2 | run_i: 0 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 2 | run_i: 0 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 2 | run_i: 0 | + k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 2 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 2 | run_i: 0 | + v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 2 | run_i: 0 | = v_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 2 | run_i: 0 | _attn | v size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 6, 6])\n",
      "layer_num: 2 | run_i: 0 | dump is not none\n",
      "layer_num: 2 | run_i: 0 | w_sizetorch.Size([1, 12, 6, 6])\n",
      "layer_num: 2 | run_i: 0 | v_sizetorch.Size([1, 12, 6, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 2 | run_i: 1 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 2 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 2 | run_i: 1 | - kv_same: True\n",
      "layer_num: 2 | run_i: 1 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 2 | run_i: 1 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 2 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 6, 3])\n",
      "layer_num: 2 | run_i: 1 | dump is not none\n",
      "layer_num: 2 | run_i: 1 | w_sizetorch.Size([1, 12, 6, 3])\n",
      "layer_num: 2 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 3 | run_i: 0 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 3 | run_i: 0 | - k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 3 | run_i: 0 | - v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 3 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 3 | run_i: 0 | - kv_same: True\n",
      "layer_num: 3 | run_i: 0 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 3 | run_i: 0 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 3 | run_i: 0 | + k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 3 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 3 | run_i: 0 | + v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 3 | run_i: 0 | = v_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 3 | run_i: 0 | _attn | v size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 6, 6])\n",
      "layer_num: 3 | run_i: 0 | dump is not none\n",
      "layer_num: 3 | run_i: 0 | w_sizetorch.Size([1, 12, 6, 6])\n",
      "layer_num: 3 | run_i: 0 | v_sizetorch.Size([1, 12, 6, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 3 | run_i: 1 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 3 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 3 | run_i: 1 | - kv_same: True\n",
      "layer_num: 3 | run_i: 1 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 3 | run_i: 1 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 3 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 6, 3])\n",
      "layer_num: 3 | run_i: 1 | dump is not none\n",
      "layer_num: 3 | run_i: 1 | w_sizetorch.Size([1, 12, 6, 3])\n",
      "layer_num: 3 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 4 | run_i: 0 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 4 | run_i: 0 | - k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 4 | run_i: 0 | - v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 4 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 4 | run_i: 0 | - kv_same: True\n",
      "layer_num: 4 | run_i: 0 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 4 | run_i: 0 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 4 | run_i: 0 | + k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 4 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 4 | run_i: 0 | + v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 4 | run_i: 0 | = v_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 4 | run_i: 0 | _attn | v size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 6, 6])\n",
      "layer_num: 4 | run_i: 0 | dump is not none\n",
      "layer_num: 4 | run_i: 0 | w_sizetorch.Size([1, 12, 6, 6])\n",
      "layer_num: 4 | run_i: 0 | v_sizetorch.Size([1, 12, 6, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 4 | run_i: 1 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 4 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 4 | run_i: 1 | - kv_same: True\n",
      "layer_num: 4 | run_i: 1 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 4 | run_i: 1 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 4 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 6, 3])\n",
      "layer_num: 4 | run_i: 1 | dump is not none\n",
      "layer_num: 4 | run_i: 1 | w_sizetorch.Size([1, 12, 6, 3])\n",
      "layer_num: 4 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 6, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_num: 5 | run_i: 0 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 5 | run_i: 0 | - k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 5 | run_i: 0 | - v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 5 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 5 | run_i: 0 | - kv_same: True\n",
      "layer_num: 5 | run_i: 0 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 5 | run_i: 0 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 5 | run_i: 0 | + k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 5 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 5 | run_i: 0 | + v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 5 | run_i: 0 | = v_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 5 | run_i: 0 | _attn | v size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 6, 6])\n",
      "layer_num: 5 | run_i: 0 | dump is not none\n",
      "layer_num: 5 | run_i: 0 | w_sizetorch.Size([1, 12, 6, 6])\n",
      "layer_num: 5 | run_i: 0 | v_sizetorch.Size([1, 12, 6, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 5 | run_i: 1 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 5 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 5 | run_i: 1 | - kv_same: True\n",
      "layer_num: 5 | run_i: 1 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 5 | run_i: 1 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 5 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 6, 3])\n",
      "layer_num: 5 | run_i: 1 | dump is not none\n",
      "layer_num: 5 | run_i: 1 | w_sizetorch.Size([1, 12, 6, 3])\n",
      "layer_num: 5 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 6 | run_i: 0 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 6 | run_i: 0 | - k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 6 | run_i: 0 | - v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 6 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 6 | run_i: 0 | - kv_same: True\n",
      "layer_num: 6 | run_i: 0 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 6 | run_i: 0 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 6 | run_i: 0 | + k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 6 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 6 | run_i: 0 | + v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 6 | run_i: 0 | = v_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 6 | run_i: 0 | _attn | v size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 6, 6])\n",
      "layer_num: 6 | run_i: 0 | dump is not none\n",
      "layer_num: 6 | run_i: 0 | w_sizetorch.Size([1, 12, 6, 6])\n",
      "layer_num: 6 | run_i: 0 | v_sizetorch.Size([1, 12, 6, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 6 | run_i: 1 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 6 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 6 | run_i: 1 | - kv_same: True\n",
      "layer_num: 6 | run_i: 1 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 6 | run_i: 1 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 6 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 6, 3])\n",
      "layer_num: 6 | run_i: 1 | dump is not none\n",
      "layer_num: 6 | run_i: 1 | w_sizetorch.Size([1, 12, 6, 3])\n",
      "layer_num: 6 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 7 | run_i: 0 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 7 | run_i: 0 | - k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 7 | run_i: 0 | - v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 7 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 7 | run_i: 0 | - kv_same: True\n",
      "layer_num: 7 | run_i: 0 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 7 | run_i: 0 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 7 | run_i: 0 | + k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 7 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 7 | run_i: 0 | + v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 7 | run_i: 0 | = v_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 7 | run_i: 0 | _attn | v size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 6, 6])\n",
      "layer_num: 7 | run_i: 0 | dump is not none\n",
      "layer_num: 7 | run_i: 0 | w_sizetorch.Size([1, 12, 6, 6])\n",
      "layer_num: 7 | run_i: 0 | v_sizetorch.Size([1, 12, 6, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 7 | run_i: 1 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 7 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 7 | run_i: 1 | - kv_same: True\n",
      "layer_num: 7 | run_i: 1 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 7 | run_i: 1 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 7 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 6, 3])\n",
      "layer_num: 7 | run_i: 1 | dump is not none\n",
      "layer_num: 7 | run_i: 1 | w_sizetorch.Size([1, 12, 6, 3])\n",
      "layer_num: 7 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 8 | run_i: 0 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 8 | run_i: 0 | - k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 8 | run_i: 0 | - v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 8 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 8 | run_i: 0 | - kv_same: True\n",
      "layer_num: 8 | run_i: 0 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 8 | run_i: 0 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 8 | run_i: 0 | + k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 8 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 8 | run_i: 0 | + v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 8 | run_i: 0 | = v_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 8 | run_i: 0 | _attn | v size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 6, 6])\n",
      "layer_num: 8 | run_i: 0 | dump is not none\n",
      "layer_num: 8 | run_i: 0 | w_sizetorch.Size([1, 12, 6, 6])\n",
      "layer_num: 8 | run_i: 0 | v_sizetorch.Size([1, 12, 6, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 8 | run_i: 1 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 8 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 8 | run_i: 1 | - kv_same: True\n",
      "layer_num: 8 | run_i: 1 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 8 | run_i: 1 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 8 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 6, 3])\n",
      "layer_num: 8 | run_i: 1 | dump is not none\n",
      "layer_num: 8 | run_i: 1 | w_sizetorch.Size([1, 12, 6, 3])\n",
      "layer_num: 8 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 9 | run_i: 0 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 9 | run_i: 0 | - k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 9 | run_i: 0 | - v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 9 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 9 | run_i: 0 | - kv_same: True\n",
      "layer_num: 9 | run_i: 0 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 9 | run_i: 0 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 9 | run_i: 0 | + k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 9 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 9 | run_i: 0 | + v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 9 | run_i: 0 | = v_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 9 | run_i: 0 | _attn | v size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 6, 6])\n",
      "layer_num: 9 | run_i: 0 | dump is not none\n",
      "layer_num: 9 | run_i: 0 | w_sizetorch.Size([1, 12, 6, 6])\n",
      "layer_num: 9 | run_i: 0 | v_sizetorch.Size([1, 12, 6, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 9 | run_i: 1 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 9 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 9 | run_i: 1 | - kv_same: True\n",
      "layer_num: 9 | run_i: 1 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 9 | run_i: 1 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 9 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 6, 3])\n",
      "layer_num: 9 | run_i: 1 | dump is not none\n",
      "layer_num: 9 | run_i: 1 | w_sizetorch.Size([1, 12, 6, 3])\n",
      "layer_num: 9 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 10 | run_i: 0 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 10 | run_i: 0 | - k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 10 | run_i: 0 | - v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 10 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 10 | run_i: 0 | - kv_same: True\n",
      "layer_num: 10 | run_i: 0 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 10 | run_i: 0 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 10 | run_i: 0 | + k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 10 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 10 | run_i: 0 | + v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 10 | run_i: 0 | = v_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 10 | run_i: 0 | _attn | v size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 6, 6])\n",
      "layer_num: 10 | run_i: 0 | dump is not none\n",
      "layer_num: 10 | run_i: 0 | w_sizetorch.Size([1, 12, 6, 6])\n",
      "layer_num: 10 | run_i: 0 | v_sizetorch.Size([1, 12, 6, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 10 | run_i: 1 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 10 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 10 | run_i: 1 | - kv_same: True\n",
      "layer_num: 10 | run_i: 1 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 10 | run_i: 1 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 10 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 6, 3])\n",
      "layer_num: 10 | run_i: 1 | dump is not none\n",
      "layer_num: 10 | run_i: 1 | w_sizetorch.Size([1, 12, 6, 3])\n",
      "layer_num: 10 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 11 | run_i: 0 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 11 | run_i: 0 | - k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 11 | run_i: 0 | - v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 11 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 11 | run_i: 0 | - kv_same: True\n",
      "layer_num: 11 | run_i: 0 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 11 | run_i: 0 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 11 | run_i: 0 | + k_size: torch.Size([1, 6, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 11 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 11 | run_i: 0 | + v_size: torch.Size([1, 6, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 11 | run_i: 0 | = v_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 6])\n",
      "layer_num: 11 | run_i: 0 | _attn | v size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 6, 6])\n",
      "layer_num: 11 | run_i: 0 | dump is not none\n",
      "layer_num: 11 | run_i: 0 | w_sizetorch.Size([1, 12, 6, 6])\n",
      "layer_num: 11 | run_i: 0 | v_sizetorch.Size([1, 12, 6, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 11 | run_i: 1 | - q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 11 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 11 | run_i: 1 | - kv_same: True\n",
      "layer_num: 11 | run_i: 1 | + q_size: torch.Size([1, 6, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 6, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 6, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 11 | run_i: 1 | = q_size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 11 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | q size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 6, 3])\n",
      "layer_num: 11 | run_i: 1 | dump is not none\n",
      "layer_num: 11 | run_i: 1 | w_sizetorch.Size([1, 12, 6, 3])\n",
      "layer_num: 11 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 6, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 6, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 6, 768])\n",
      "layer_num: 0 | run_i: 0 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 0 | run_i: 0 | - k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 0 | run_i: 0 | - v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 0 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 0 | run_i: 0 | - kv_same: True\n",
      "layer_num: 0 | run_i: 0 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 0 | run_i: 0 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 0 | run_i: 0 | + k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 0 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 0 | run_i: 0 | + v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 0 | run_i: 0 | = v_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 0 | run_i: 0 | _attn | v size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 0 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 7, 7])\n",
      "layer_num: 0 | run_i: 0 | dump is not none\n",
      "layer_num: 0 | run_i: 0 | w_sizetorch.Size([1, 12, 7, 7])\n",
      "layer_num: 0 | run_i: 0 | v_sizetorch.Size([1, 12, 7, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 0 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 0 | run_i: 1 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 0 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 0 | run_i: 1 | - kv_same: True\n",
      "layer_num: 0 | run_i: 1 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 0 | run_i: 1 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 0 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 0 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 7, 3])\n",
      "layer_num: 0 | run_i: 1 | dump is not none\n",
      "layer_num: 0 | run_i: 1 | w_sizetorch.Size([1, 12, 7, 3])\n",
      "layer_num: 0 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 0 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 1 | run_i: 0 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 1 | run_i: 0 | - k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 1 | run_i: 0 | - v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 1 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 1 | run_i: 0 | - kv_same: True\n",
      "layer_num: 1 | run_i: 0 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 1 | run_i: 0 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 1 | run_i: 0 | + k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 1 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 1 | run_i: 0 | + v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 1 | run_i: 0 | = v_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 1 | run_i: 0 | _attn | v size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 1 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 7, 7])\n",
      "layer_num: 1 | run_i: 0 | dump is not none\n",
      "layer_num: 1 | run_i: 0 | w_sizetorch.Size([1, 12, 7, 7])\n",
      "layer_num: 1 | run_i: 0 | v_sizetorch.Size([1, 12, 7, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 1 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 1 | run_i: 1 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 1 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 1 | run_i: 1 | - kv_same: True\n",
      "layer_num: 1 | run_i: 1 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 1 | run_i: 1 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 1 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 1 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 7, 3])\n",
      "layer_num: 1 | run_i: 1 | dump is not none\n",
      "layer_num: 1 | run_i: 1 | w_sizetorch.Size([1, 12, 7, 3])\n",
      "layer_num: 1 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 1 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 2 | run_i: 0 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 2 | run_i: 0 | - k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 2 | run_i: 0 | - v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 2 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 2 | run_i: 0 | - kv_same: True\n",
      "layer_num: 2 | run_i: 0 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 2 | run_i: 0 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 2 | run_i: 0 | + k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 2 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 2 | run_i: 0 | + v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 2 | run_i: 0 | = v_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 2 | run_i: 0 | _attn | v size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 2 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 7, 7])\n",
      "layer_num: 2 | run_i: 0 | dump is not none\n",
      "layer_num: 2 | run_i: 0 | w_sizetorch.Size([1, 12, 7, 7])\n",
      "layer_num: 2 | run_i: 0 | v_sizetorch.Size([1, 12, 7, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 2 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 2 | run_i: 1 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 2 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 2 | run_i: 1 | - kv_same: True\n",
      "layer_num: 2 | run_i: 1 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 2 | run_i: 1 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 2 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 2 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 7, 3])\n",
      "layer_num: 2 | run_i: 1 | dump is not none\n",
      "layer_num: 2 | run_i: 1 | w_sizetorch.Size([1, 12, 7, 3])\n",
      "layer_num: 2 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 2 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 3 | run_i: 0 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 3 | run_i: 0 | - k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 3 | run_i: 0 | - v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 3 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 3 | run_i: 0 | - kv_same: True\n",
      "layer_num: 3 | run_i: 0 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 3 | run_i: 0 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 3 | run_i: 0 | + k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 3 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 3 | run_i: 0 | + v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 3 | run_i: 0 | = v_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 3 | run_i: 0 | _attn | v size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 3 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 7, 7])\n",
      "layer_num: 3 | run_i: 0 | dump is not none\n",
      "layer_num: 3 | run_i: 0 | w_sizetorch.Size([1, 12, 7, 7])\n",
      "layer_num: 3 | run_i: 0 | v_sizetorch.Size([1, 12, 7, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 3 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 3 | run_i: 1 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 3 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 3 | run_i: 1 | - kv_same: True\n",
      "layer_num: 3 | run_i: 1 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 3 | run_i: 1 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 3 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 3 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 7, 3])\n",
      "layer_num: 3 | run_i: 1 | dump is not none\n",
      "layer_num: 3 | run_i: 1 | w_sizetorch.Size([1, 12, 7, 3])\n",
      "layer_num: 3 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 3 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 4 | run_i: 0 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 4 | run_i: 0 | - k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 4 | run_i: 0 | - v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 4 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 4 | run_i: 0 | - kv_same: True\n",
      "layer_num: 4 | run_i: 0 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 4 | run_i: 0 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 4 | run_i: 0 | + k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 4 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 4 | run_i: 0 | + v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 4 | run_i: 0 | = v_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 4 | run_i: 0 | _attn | v size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 4 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 7, 7])\n",
      "layer_num: 4 | run_i: 0 | dump is not none\n",
      "layer_num: 4 | run_i: 0 | w_sizetorch.Size([1, 12, 7, 7])\n",
      "layer_num: 4 | run_i: 0 | v_sizetorch.Size([1, 12, 7, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 4 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 4 | run_i: 1 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 4 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 4 | run_i: 1 | - kv_same: True\n",
      "layer_num: 4 | run_i: 1 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 4 | run_i: 1 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 4 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 4 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 7, 3])\n",
      "layer_num: 4 | run_i: 1 | dump is not none\n",
      "layer_num: 4 | run_i: 1 | w_sizetorch.Size([1, 12, 7, 3])\n",
      "layer_num: 4 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 4 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 5 | run_i: 0 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 5 | run_i: 0 | - k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 5 | run_i: 0 | - v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 5 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 5 | run_i: 0 | - kv_same: True\n",
      "layer_num: 5 | run_i: 0 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 5 | run_i: 0 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 5 | run_i: 0 | + k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 5 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 5 | run_i: 0 | + v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 5 | run_i: 0 | = v_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 5 | run_i: 0 | _attn | v size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 5 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 7, 7])\n",
      "layer_num: 5 | run_i: 0 | dump is not none\n",
      "layer_num: 5 | run_i: 0 | w_sizetorch.Size([1, 12, 7, 7])\n",
      "layer_num: 5 | run_i: 0 | v_sizetorch.Size([1, 12, 7, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 5 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 5 | run_i: 1 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 5 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 5 | run_i: 1 | - kv_same: True\n",
      "layer_num: 5 | run_i: 1 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 5 | run_i: 1 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 5 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 5 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 7, 3])\n",
      "layer_num: 5 | run_i: 1 | dump is not none\n",
      "layer_num: 5 | run_i: 1 | w_sizetorch.Size([1, 12, 7, 3])\n",
      "layer_num: 5 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 5 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 6 | run_i: 0 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 6 | run_i: 0 | - k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 6 | run_i: 0 | - v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 6 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 6 | run_i: 0 | - kv_same: True\n",
      "layer_num: 6 | run_i: 0 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 6 | run_i: 0 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 6 | run_i: 0 | + k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 6 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 6 | run_i: 0 | + v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 6 | run_i: 0 | = v_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 6 | run_i: 0 | _attn | v size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 6 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 7, 7])\n",
      "layer_num: 6 | run_i: 0 | dump is not none\n",
      "layer_num: 6 | run_i: 0 | w_sizetorch.Size([1, 12, 7, 7])\n",
      "layer_num: 6 | run_i: 0 | v_sizetorch.Size([1, 12, 7, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 6 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 6 | run_i: 1 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 6 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 6 | run_i: 1 | - kv_same: True\n",
      "layer_num: 6 | run_i: 1 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 6 | run_i: 1 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 6 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 6 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 7, 3])\n",
      "layer_num: 6 | run_i: 1 | dump is not none\n",
      "layer_num: 6 | run_i: 1 | w_sizetorch.Size([1, 12, 7, 3])\n",
      "layer_num: 6 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 6 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 7 | run_i: 0 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 7 | run_i: 0 | - k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 7 | run_i: 0 | - v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 7 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 7 | run_i: 0 | - kv_same: True\n",
      "layer_num: 7 | run_i: 0 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 7 | run_i: 0 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 7 | run_i: 0 | + k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 7 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 7 | run_i: 0 | + v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 7 | run_i: 0 | = v_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 7 | run_i: 0 | _attn | v size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 7 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 7, 7])\n",
      "layer_num: 7 | run_i: 0 | dump is not none\n",
      "layer_num: 7 | run_i: 0 | w_sizetorch.Size([1, 12, 7, 7])\n",
      "layer_num: 7 | run_i: 0 | v_sizetorch.Size([1, 12, 7, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 7 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 7 | run_i: 1 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 7 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 7 | run_i: 1 | - kv_same: True\n",
      "layer_num: 7 | run_i: 1 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 7 | run_i: 1 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 7 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 7 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 7, 3])\n",
      "layer_num: 7 | run_i: 1 | dump is not none\n",
      "layer_num: 7 | run_i: 1 | w_sizetorch.Size([1, 12, 7, 3])\n",
      "layer_num: 7 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 7 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 8 | run_i: 0 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 8 | run_i: 0 | - k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 8 | run_i: 0 | - v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 8 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 8 | run_i: 0 | - kv_same: True\n",
      "layer_num: 8 | run_i: 0 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 8 | run_i: 0 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 8 | run_i: 0 | + k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 8 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 8 | run_i: 0 | + v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 8 | run_i: 0 | = v_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 8 | run_i: 0 | _attn | v size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 8 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 7, 7])\n",
      "layer_num: 8 | run_i: 0 | dump is not none\n",
      "layer_num: 8 | run_i: 0 | w_sizetorch.Size([1, 12, 7, 7])\n",
      "layer_num: 8 | run_i: 0 | v_sizetorch.Size([1, 12, 7, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 8 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 8 | run_i: 1 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 8 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 8 | run_i: 1 | - kv_same: True\n",
      "layer_num: 8 | run_i: 1 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 8 | run_i: 1 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 8 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 8 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 7, 3])\n",
      "layer_num: 8 | run_i: 1 | dump is not none\n",
      "layer_num: 8 | run_i: 1 | w_sizetorch.Size([1, 12, 7, 3])\n",
      "layer_num: 8 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 8 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 9 | run_i: 0 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 9 | run_i: 0 | - k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 9 | run_i: 0 | - v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 9 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 9 | run_i: 0 | - kv_same: True\n",
      "layer_num: 9 | run_i: 0 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 9 | run_i: 0 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 9 | run_i: 0 | + k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 9 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 9 | run_i: 0 | + v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 9 | run_i: 0 | = v_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 9 | run_i: 0 | _attn | v size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 9 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 7, 7])\n",
      "layer_num: 9 | run_i: 0 | dump is not none\n",
      "layer_num: 9 | run_i: 0 | w_sizetorch.Size([1, 12, 7, 7])\n",
      "layer_num: 9 | run_i: 0 | v_sizetorch.Size([1, 12, 7, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 9 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 9 | run_i: 1 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 9 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 9 | run_i: 1 | - kv_same: True\n",
      "layer_num: 9 | run_i: 1 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 9 | run_i: 1 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 9 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 9 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 7, 3])\n",
      "layer_num: 9 | run_i: 1 | dump is not none\n",
      "layer_num: 9 | run_i: 1 | w_sizetorch.Size([1, 12, 7, 3])\n",
      "layer_num: 9 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 9 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 10 | run_i: 0 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 10 | run_i: 0 | - k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 10 | run_i: 0 | - v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 10 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 10 | run_i: 0 | - kv_same: True\n",
      "layer_num: 10 | run_i: 0 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 10 | run_i: 0 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 10 | run_i: 0 | + k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 10 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 10 | run_i: 0 | + v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 10 | run_i: 0 | = v_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 10 | run_i: 0 | _attn | v size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 10 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 7, 7])\n",
      "layer_num: 10 | run_i: 0 | dump is not none\n",
      "layer_num: 10 | run_i: 0 | w_sizetorch.Size([1, 12, 7, 7])\n",
      "layer_num: 10 | run_i: 0 | v_sizetorch.Size([1, 12, 7, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 10 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 10 | run_i: 1 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 10 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 10 | run_i: 1 | - kv_same: True\n",
      "layer_num: 10 | run_i: 1 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 10 | run_i: 1 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 10 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 10 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 7, 3])\n",
      "layer_num: 10 | run_i: 1 | dump is not none\n",
      "layer_num: 10 | run_i: 1 | w_sizetorch.Size([1, 12, 7, 3])\n",
      "layer_num: 10 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 10 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 11 | run_i: 0 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 11 | run_i: 0 | - k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 11 | run_i: 0 | - v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 11 | run_i: 0 | - qkv_same: True\n",
      "layer_num: 11 | run_i: 0 | - kv_same: True\n",
      "layer_num: 11 | run_i: 0 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 11 | run_i: 0 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 11 | run_i: 0 | + k_size: torch.Size([1, 7, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 11 | run_i: 0 | = k_size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 11 | run_i: 0 | + v_size: torch.Size([1, 7, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 11 | run_i: 0 | = v_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | k size: torch.Size([1, 12, 64, 7])\n",
      "layer_num: 11 | run_i: 0 | _attn | v size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 11 | run_i: 0 | _attn | w = q * k: torch.Size([1, 12, 7, 7])\n",
      "layer_num: 11 | run_i: 0 | dump is not none\n",
      "layer_num: 11 | run_i: 0 | w_sizetorch.Size([1, 12, 7, 7])\n",
      "layer_num: 11 | run_i: 0 | v_sizetorch.Size([1, 12, 7, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 11 | run_i: 0 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "layer_num: 11 | run_i: 1 | - q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 11 | run_i: 1 | - k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | - v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | - qkv_same: False\n",
      "layer_num: 11 | run_i: 1 | - kv_same: True\n",
      "layer_num: 11 | run_i: 1 | + q_size: torch.Size([1, 7, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 7, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 7, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 11 | run_i: 1 | = q_size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 11 | run_i: 1 | + k_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | = k_size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | + v_size: torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | input x size: x (batch_size, seq_len, num_features) torch.Size([1, 3, 768])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | view x size: x (batch_size, seq_len, self.n_heads, num_features // self.n_heads) torch.Size([1, 3, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _split_heads | permute x size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | = v_size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | q size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | k size: torch.Size([1, 12, 64, 3])\n",
      "layer_num: 11 | run_i: 1 | _attn | v size: torch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _attn | w = q * k: torch.Size([1, 12, 7, 3])\n",
      "layer_num: 11 | run_i: 1 | dump is not none\n",
      "layer_num: 11 | run_i: 1 | w_sizetorch.Size([1, 12, 7, 3])\n",
      "layer_num: 11 | run_i: 1 | v_sizetorch.Size([1, 12, 3, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | input x size: torch.Size([1, 12, 7, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | permute x size: torch.Size([1, 7, 12, 64])\n",
      "layer_num: 11 | run_i: 1 | _merge_heads | view x size: torch.Size([1, 7, 768])\n",
      "B: hi , how are you ? \n"
     ]
    }
   ],
   "source": [
    "dump = simple_interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello</w>'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.id2token[3578]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input info string: i am software developer.\n",
      "Input info indexes: [3, 257, 1056, 15540, 4305, 6495, 247, 4]\n",
      "Input info tokens: ['<i>', 'i</w>', 'am</w>', 'software</w>', 'devel', 'oper</w>', '.</w>', '</i>']\n"
     ]
    }
   ],
   "source": [
    "input_info_string = 'i am software developer.'\n",
    "input_info_ids = [vocab.info_bos_id] + vocab.string2ids(input_info_string) + [vocab.info_eos_id]\n",
    "input_info_tokens = [vocab.id2token[i] for i in input_info_ids]\n",
    "\n",
    "print(f'Input info string: {input_info_string}')\n",
    "print(f'Input info indexes: {input_info_ids}')\n",
    "print(f'Input info tokens: {input_info_tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dialog string: hi, who are you?\n",
      "Input dialog indexes: [5, 3577, 248, 771, 648, 520, 265, 6]\n",
      "Input dialog tokens: ['<t1>', 'hi</w>', ',</w>', 'who</w>', 'are</w>', 'you</w>', '?</w>', '</t1>']\n"
     ]
    }
   ],
   "source": [
    "input_dialog_string = 'hi, who are you?'\n",
    "input_dialog_ids = [vocab.talker1_bos_id] + vocab.string2ids(input_dialog_string) + [vocab.talker1_eos_id]\n",
    "input_dialog_tokens = [vocab.id2token[i] for i in input_dialog_ids]\n",
    "\n",
    "print(f'Input dialog string: {input_dialog_string}')\n",
    "print(f'Input dialog indexes: {input_dialog_ids}')\n",
    "print(f'Input dialog tokens: {input_dialog_tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_layers = 12\n",
    "n_heads = 12\n",
    "n_context = 3\n",
    "\n",
    "n = 0\n",
    "\n",
    "out_ids = []\n",
    "\n",
    "dialog_weights = np.zeros((n_layers, n_heads, len(input_dialog_tokens), len(dump)))\n",
    "info_weights = np.zeros((n_layers, n_heads, len(input_info_tokens), len(dump)))\n",
    "self_weights = np.zeros((n_layers, n_heads, len(dump), len(dump))) + np.nan\n",
    "\n",
    "for i, (idx, d) in enumerate(dump):\n",
    "    out_ids.append(idx)\n",
    "    \n",
    "    for l_i, l in enumerate(range(n, n_context * n_layers, n_context)):\n",
    "        for h in range(n_heads):\n",
    "            \n",
    "            current_dump = d[l]\n",
    "            \n",
    "            self_weights[l_i, h, :i+1, i] = current_dump[2][0, h, -1].numpy()\n",
    "            \n",
    "            current_dump = d[l+1]\n",
    "            \n",
    "            assert current_dump[0] == l_i\n",
    "            assert current_dump[1] == 1, f' {l_i}, {l}, {current_dump[1]} 1'\n",
    "            \n",
    "            info_weights[l_i, h, :, i] = current_dump[2][0, h, -1].numpy()\n",
    "            \n",
    "            current_dump = d[l+2]\n",
    "            \n",
    "            dialog_weights[l_i, h, :, i] = current_dump[2][0, h, -1].numpy()\n",
    "#     weights.append(d[23][2][0, 11, -1].numpy().reshape(-1, 1))\n",
    "#     print(f'indx: {i} | indx2str: {vocab.id2token[i]} | {d[23][2][0, 11, -1].size()}')\n",
    "\n",
    "out_ids = [vocab.bos_id] + out_ids\n",
    "out_tokens = [vocab.id2token[i] for i in out_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 8, 14)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialog_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 8, 14)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 14, 14)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "\n",
    "# for l_i, h_i in product(range(11, weights.shape[0]), range(weights.shape[1])):\n",
    "#     plot_heatmap(weights[l_i, h_i], input_tokens, out_tokens[1:], title=f'layer {l_i + 1} | head {h_i + 1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:106: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_heatmap(weights[11, 11], input_tokens, out_tokens, title='layer 12 | head 12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(data, row_labels, col_labels, title=''):\n",
    "    fig, ax = plt.subplots(len(row_labels), 1, figsize=(14, 18))\n",
    "    \n",
    "    print(ax)\n",
    "    \n",
    "    for i, (d, r) in enumerate(zip(data, row_labels)):\n",
    "        im, cbar = heatmap(d, r, col_labels,  ax=ax[i], cmap=\"YlGn\", cbarlabel=title)\n",
    "        texts = annotate_heatmap(im, valfmt=\"{x:.1f} t\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3713b8759cc14d5ba17c0ae448b1ade6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='layer', max=11), IntSlider(value=1, description='head', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %matplotlib interactive\n",
    "\n",
    "\n",
    "from ipywidgets import interactive\n",
    "\n",
    "\n",
    "def interactive_plot(layer=1, head=1):\n",
    "    plot_heatmap([self_weights[layer, head],\n",
    "                  dialog_weights[layer, head], \n",
    "                  info_weights[layer, head]], \n",
    "                 [out_tokens,\n",
    "                  input_dialog_tokens, \n",
    "                  input_info_tokens], \n",
    "                 out_tokens[1:], title=f'layer {layer} | head {head}')\n",
    "    \n",
    "    \n",
    "interactive(interactive_plot, layer=(0, 11, 1), head=(0, 11, 1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96704a7896c4f689e5b79e607e3fe54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='layer', max=11), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def interactive_average_plot(layer=1):\n",
    "    plot_heatmap([np.mean(self_weights[layer, :], axis=0),\n",
    "                  np.mean(dialog_weights[layer, :], axis=0), \n",
    "                  np.mean(info_weights[layer, :], axis=0)], \n",
    "                 [out_tokens,\n",
    "                  input_dialog_tokens, \n",
    "                  input_info_tokens], \n",
    "                 out_tokens[1:], title=f'layer {layer}')\n",
    "    \n",
    "    \n",
    "interactive(interactive_average_plot, layer=(0, 11, 1), head=(0, 11, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
