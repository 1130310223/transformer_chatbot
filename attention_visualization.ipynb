{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data, row_labels, col_labels, ax=None,\n",
    "            cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "\n",
    "    Arguments:\n",
    "        data       : A 2D numpy array of shape (N,M)\n",
    "        row_labels : A list or array of length N with the labels\n",
    "                     for the rows\n",
    "        col_labels : A list or array of length M with the labels\n",
    "                     for the columns\n",
    "    Optional arguments:\n",
    "        ax         : A matplotlib.axes.Axes instance to which the heatmap\n",
    "                     is plotted. If not provided, use current axes or\n",
    "                     create a new one.\n",
    "        cbar_kw    : A dictionary with arguments to\n",
    "                     :meth:`matplotlib.Figure.colorbar`.\n",
    "        cbarlabel  : The label for the colorbar\n",
    "    All other arguments are directly passed on to the imshow call.\n",
    "    \"\"\"\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    # ... and label them with the respective list entries.\n",
    "    ax.set_xticklabels(col_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False,\n",
    "                   labeltop=True, labelbottom=False)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    for edge, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    return im, cbar\n",
    "\n",
    "\n",
    "def annotate_heatmap(im, data=None, valfmt=\"{x:.2f}\",\n",
    "                     textcolors=[\"black\", \"white\"],\n",
    "                     threshold=None, **textkw):\n",
    "    \"\"\"\n",
    "    A function to annotate a heatmap.\n",
    "\n",
    "    Arguments:\n",
    "        im         : The AxesImage to be labeled.\n",
    "    Optional arguments:\n",
    "        data       : Data used to annotate. If None, the image's data is used.\n",
    "        valfmt     : The format of the annotations inside the heatmap.\n",
    "                     This should either use the string format method, e.g.\n",
    "                     \"$ {x:.2f}\", or be a :class:`matplotlib.ticker.Formatter`.\n",
    "        textcolors : A list or array of two color specifications. The first is\n",
    "                     used for values below a threshold, the second for those\n",
    "                     above.\n",
    "        threshold  : Value in data units according to which the colors from\n",
    "                     textcolors are applied. If None (the default) uses the\n",
    "                     middle of the colormap as separation.\n",
    "\n",
    "    Further arguments are passed on to the created text labels.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[im.norm(data[i, j]) > threshold])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mkdir checkpoints\n",
    "!wget -O checkpoints/last_checkpoint https://www.dropbox.com/s/cs6zd9yntn6ixea/last_checkpoint?dl=1\n",
    "\n",
    "!wget -O parameters.zip https://www.dropbox.com/s/n2jbjyq32x6jgr6/parameters.zip?dl=1\n",
    "!unzip parameters.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.transformer_model import TransformerModel\n",
    "from model.text import BPEVocab\n",
    "from model.utils import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import get_model_config\n",
    "model_config = get_model_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annealing': 0,\n",
      " 'annealing_topk': None,\n",
      " 'attn_dropout': 0.1,\n",
      " 'beam_size': 3,\n",
      " 'bpe_codes_path': './parameters/bpe.code',\n",
      " 'bpe_vocab_path': './parameters/bpe.vocab',\n",
      " 'checkpoint_path': './checkpoints/last_checkpoint',\n",
      " 'diversity_coef': 0,\n",
      " 'diversity_groups': 1,\n",
      " 'dropout': 0.1,\n",
      " 'embed_dropout': 0.1,\n",
      " 'embeddings_size': 768,\n",
      " 'ff_dropout': 0.1,\n",
      " 'length_penalty': 0.6,\n",
      " 'max_seq_len': 256,\n",
      " 'n_heads': 12,\n",
      " 'n_layers': 12,\n",
      " 'n_pos_embeddings': 512,\n",
      " 'n_segments': None}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = BPEVocab.from_files(model_config.bpe_vocab_path, model_config.bpe_codes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(n_layers=model_config.n_layers,\n",
    "                         n_embeddings=len(vocab),\n",
    "                         n_pos_embeddings=model_config.n_pos_embeddings,\n",
    "                         embeddings_size=model_config.embeddings_size,\n",
    "                         padding_idx=vocab.pad_id,\n",
    "                         n_heads=model_config.n_heads,\n",
    "                         dropout=model_config.dropout,\n",
    "                         embed_dropout=model_config.embed_dropout,\n",
    "                         attn_dropout=model_config.attn_dropout,\n",
    "                         ff_dropout=model_config.ff_dropout,\n",
    "                         bos_id=vocab.bos_id,\n",
    "                         eos_id=vocab.eos_id,\n",
    "                         max_seq_len=256,\n",
    "                         beam_size=3,\n",
    "                         length_penalty=0.6,\n",
    "                         n_segments=model_config.n_segments,\n",
    "                         sample=False,\n",
    "                         annealing_topk=None,\n",
    "                         annealing=0.6,\n",
    "                         diversity_coef=0,\n",
    "                         diversity_groups=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "state_dict = torch.load(model_config.checkpoint_path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "if 'model' in state_dict:\n",
    "    state_dict = state_dict['model']\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_responce(encoded_context, max_len=255):\n",
    "    prevs = [[vocab.bos_id]]\n",
    "    \n",
    "    dump = []\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        prevs_t = torch.tensor(prevs, dtype=torch.long, device=device)\n",
    "        \n",
    "        current_dump = []\n",
    "        outputs = model.decode(prevs_t, encoded_context, dump=current_dump)\n",
    "\n",
    "        _, m_idx = torch.max(outputs[:, -1, :], dim=-1)\n",
    "        m_idx = m_idx.item()\n",
    "        \n",
    "        dump.append((m_idx, current_dump))\n",
    "\n",
    "        prevs[0].append(m_idx)\n",
    "\n",
    "        if m_idx == vocab.eos_id:\n",
    "            break\n",
    "    return prevs[0], dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_info(max_sequences=4, max_len=255):\n",
    "    info = []\n",
    "    for _ in range(max_sequences):\n",
    "        new_info = input('Info: ').lower().strip()\n",
    "        \n",
    "        if new_info == 'exit':\n",
    "            break\n",
    "        \n",
    "        if not new_info.endswith('.'):\n",
    "            new_info += '.'\n",
    "            \n",
    "        info += vocab.string2ids(new_info)\n",
    "    \n",
    "    if info:\n",
    "        info = [vocab.info_bos_id] + info[:model.n_pos_embeddings-2] + [vocab.info_eos_id]\n",
    "        info = [torch.tensor(info, dtype=torch.long)]\n",
    "        info = pad_sequence(info, batch_first=True, padding_value=vocab.pad_id).to(device)\n",
    "        \n",
    "    return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_interactive():\n",
    "    dump = []\n",
    "    \n",
    "    info = read_info()\n",
    "    info_tokens = info.cpu().numpy()[0]\n",
    "    \n",
    "    dialog = []\n",
    "    \n",
    "    while True:\n",
    "        new_message = input('H: ').lower().strip()\n",
    "        \n",
    "        if new_message == 'exit':\n",
    "            break\n",
    "        \n",
    "        dialog += [vocab.talker1_bos_id] + vocab.string2ids(new_message) + [vocab.talker1_eos_id]\n",
    "        \n",
    "        t_dialog = [torch.tensor(dialog[-model_config.embeddings_size+1:], dtype=torch.long)]\n",
    "        t_dialog = pad_sequence(t_dialog, batch_first=True, padding_value=vocab.pad_id).to(device)\n",
    "        \n",
    "        dialog_tokens = t_dialog.cpu().numpy()[0]\n",
    "        \n",
    "        context = []\n",
    "        if len(info):\n",
    "            context.append(info)\n",
    "        context.append(t_dialog)\n",
    "\n",
    "        encoded_context = [model.encode(c) for c in context]\n",
    "        \n",
    "        res_indx, attention_dump = model_responce(encoded_context)\n",
    "        res_indx = res_indx[1:-1]\n",
    "        \n",
    "        print(f'B: {vocab.ids2string(res_indx)}')\n",
    "        \n",
    "        dump.append((attention_dump, info_tokens, dialog_tokens))\n",
    "        \n",
    "        dialog += [vocab.talker2_bos_id] + res_indx + [vocab.talker2_eos_id]\n",
    "        \n",
    "    return dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: i am form england.\n",
      "Info: i am a software developer.\n",
      "Info: exit\n",
      "H: hi, how are you?\n",
      "B: i 'm good . how are you ? \n",
      "H: i am fine. where are you from?\n",
      "B: i 'm from england . i 'm from england . \n",
      "H: exit\n"
     ]
    }
   ],
   "source": [
    "dump = simple_interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def parse_attention_dump(i_dump, *, n_layers=12, n_heads=12, n_context=3):\n",
    "    '''if info is enpty n_context=2'''\n",
    "    assert n_context == 3, 'Not implemented'\n",
    "    attention_dump, info_tokens, dialog_tokens = i_dump\n",
    "\n",
    "    out_ids = []\n",
    "\n",
    "    dialog_weights = np.zeros((n_layers, n_heads, len(dialog_tokens), len(attention_dump)))\n",
    "    info_weights = np.zeros((n_layers, n_heads, len(info_tokens), len(attention_dump)))\n",
    "    self_weights = np.zeros((n_layers, n_heads, len(attention_dump), len(attention_dump))) + np.nan\n",
    "\n",
    "    for i, (idx, d) in enumerate(attention_dump):\n",
    "        out_ids.append(idx)\n",
    "\n",
    "        for l_i, l in enumerate(range(n, n_context * n_layers, n_context)):\n",
    "            for h in range(n_heads):\n",
    "\n",
    "                current_dump = d[l]\n",
    "\n",
    "                self_weights[l_i, h, :i+1, i] = current_dump[2][0, h, -1].numpy()\n",
    "\n",
    "                current_dump = d[l+1]\n",
    "\n",
    "                assert current_dump[0] == l_i\n",
    "                assert current_dump[1] == 1, f' {l_i}, {l}, {current_dump[1]} 1'\n",
    "\n",
    "                info_weights[l_i, h, :, i] = current_dump[2][0, h, -1].numpy()\n",
    "\n",
    "                current_dump = d[l+2]\n",
    "\n",
    "                dialog_weights[l_i, h, :, i] = current_dump[2][0, h, -1].numpy()\n",
    "\n",
    "    out_ids = [vocab.bos_id] + out_ids\n",
    "    \n",
    "    return self_weights, info_weights, dialog_weights, out_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dump = []\n",
    "for dump_i in dump:\n",
    "    \n",
    "    self_weights, info_weights, dialog_weights, out_ids = parse_attention_dump(dump_i)\n",
    "    info_ids, dialog_ids = dump_i[1:]\n",
    "    \n",
    "    p_dump.append((self_weights, info_weights, dialog_weights, info_ids, dialog_ids, out_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(data, row_labels, col_labels, title=''):\n",
    "    fig, ax = plt.subplots(len(row_labels), 1, figsize=(14, 18))\n",
    "    \n",
    "    for i, (d, r) in enumerate(zip(data, row_labels)):\n",
    "        im, cbar = heatmap(d, r, col_labels,  ax=ax[i], cmap=\"YlGn\", cbarlabel=title)\n",
    "        texts = annotate_heatmap(im, valfmt=\"{x:.1f} t\")\n",
    "\n",
    "        fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbf1260d8334f5083bdc712be42820c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='iteration', max=1), IntSlider(value=1, description='laye…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %matplotlib interactive\n",
    "\n",
    "\n",
    "from ipywidgets import interactive\n",
    "\n",
    "\n",
    "def interactive_plot(iteration=0, layer=1, head=1):\n",
    "    sw = p_dump[iteration][0]\n",
    "    iw = p_dump[iteration][1]\n",
    "    dw = p_dump[iteration][2]\n",
    "    \n",
    "    it = [vocab.id2token[i] for i in p_dump[iteration][3]]\n",
    "    dt = [vocab.id2token[i] for i in p_dump[iteration][4]]\n",
    "    ot = [vocab.id2token[i] for i in p_dump[iteration][5]]\n",
    "    \n",
    "    plot_heatmap([sw[layer, head],\n",
    "                  dw[layer, head], \n",
    "                  iw[layer, head]], \n",
    "                 [ot,\n",
    "                  dt, \n",
    "                  it], \n",
    "                 ot[1:], title=f'layer {layer} | head {head}')\n",
    "    \n",
    "    \n",
    "interactive(interactive_plot, iteration=(0, len(p_dump)-1, 1), layer=(0, 11, 1), head=(0, 11, 1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38322e9e2db847a1b7c2bfabc0310bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='iteration', max=1), IntSlider(value=1, description='laye…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def interactive_average_plot(iteration=0, layer=1):\n",
    "    \n",
    "    sw = p_dump[iteration][0]\n",
    "    iw = p_dump[iteration][1]\n",
    "    dw = p_dump[iteration][2]\n",
    "    \n",
    "    it = [vocab.id2token[i] for i in p_dump[iteration][3]]\n",
    "    dt = [vocab.id2token[i] for i in p_dump[iteration][4]]\n",
    "    ot = [vocab.id2token[i] for i in p_dump[iteration][5]]\n",
    "    \n",
    "    plot_heatmap([np.mean(sw[layer, :], axis=0),\n",
    "                  np.mean(dw[layer, :], axis=0), \n",
    "                  np.mean(iw[layer, :], axis=0)], \n",
    "                 [ot,\n",
    "                  dt, \n",
    "                  it], \n",
    "                 ot[1:], title=f'layer {layer}')\n",
    "    \n",
    "    \n",
    "interactive(interactive_average_plot, iteration=(0, len(p_dump)-1, 1), layer=(0, 11, 1), head=(0, 11, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
